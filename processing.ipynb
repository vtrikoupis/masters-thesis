{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "730a29a129caaf396252390d0f158bf1f8c297b87c9b8a65cd66b7ca36b66f6f"
   }
  },
  "interpreter": {
   "hash": "730a29a129caaf396252390d0f158bf1f8c297b87c9b8a65cd66b7ca36b66f6f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Data Wrangling - Fetching step\n",
    "- The gossipcop and politifact fake and real news datasets are loaded in pandas dataframes.\n",
    "- Using urllib and bs4, the original news article is downloaded if available and relevant text is kept from the html\n",
    "- Using urllib, the twitter API is used to collect the `author_id` of fake and real news\n",
    "- Using urllib, the twitter API is used to collect the `created_at` timestamp of real and fake news\n",
    "\n",
    "Requirements:\n",
    "\n",
    "`.env` file at the root of the repo containing BEARER_TOKEN = XXX where XXX should be replaced with a Twitter API V2 token"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None \n",
    "from tqdm.notebook import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.parse import urlparse\n",
    "from urllib.error import HTTPError, URLError\n",
    "from json.decoder import JSONDecodeError\n",
    "from http.client import RemoteDisconnected\n",
    "import requests\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests import exceptions\n",
    "import logging\n",
    "from socket import timeout\n",
    "import re\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ]
  },
  {
   "source": [
    "### 1. Set up the request headers by loading the bearer token from the `.env` file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token = os.environ.get(\"BEARER_TOKEN\")\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {bearer_token}'\n",
    "}"
   ]
  },
  {
   "source": [
    "### 2. Helper functions for processing html files using beautifulsoup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = requests.Session()\n",
    "blacklisted_status_codes = [300, 301, 302, 303, 304, 305, 306, 307, 308, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 429]\n",
    "retries = Retry(connect=3, \n",
    "                backoff_factor=0.5,\n",
    "                status_forcelist=[ 500, 502, 503, 504 ])\n",
    "s.mount('http://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    return u\" \".join(t.strip() for t in visible_texts)\n",
    "\n",
    "def process_url(url):\n",
    "\n",
    "    # req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    try:\n",
    "        r = s.get(url, timeout=10, allow_redirects=False, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        if r.status_code in blacklisted_status_codes:\n",
    "            print(r.status_code)\n",
    "            return ''\n",
    "        else:\n",
    "            return text_from_html(r.text)\n",
    "    except timeout:\n",
    "        print(\"connection timedout\")\n",
    "    except requests.exceptions.ConnectionError as e:\n",
    "        print('no response')\n",
    "    except ConnectionError:\n",
    "        print(\"conn reset\")\n",
    "        print(url)\n",
    "    except RemoteDisconnected as e:\n",
    "        print(e)\n",
    "    except URLError as e:\n",
    "        print(e)\n",
    "    except HTTPError as err:\n",
    "        if err.code == 410 or 404:\n",
    "            print(\"permanently deleted or removed, url should be removed\")\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "source": [
    "### Steps 3-7 below are commented out and the previously generated output is loaded into the variables\n",
    " - `filtered_p_fake`: filtered politifact fake news with the scraped text from the original article \n",
    " - `filtered_p_real`: filtered politifact real news with the scraped text from the original article \n",
    " - `filtered_g_fake`: filtered gossipcop fake news with the scraped text from the original article \n",
    " - `filtered_g_real`: filtered gossipcop real news with the scraped text from the original article "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "politifact_fake = pd.read_csv('fakenewsnet/politifact_fake.csv')\n",
    "# filtered_p_fake = pd.read_csv('processed-data/scraped_text/politifact_fake_with_scraped_text.csv')\n",
    "\n",
    "politifact_real = pd.read_csv('fakenewsnet/politifact_real.csv')\n",
    "# filtered_p_real = pd.read_csv('processed-data/scraped_text/politifact_real_with_scraped_text.csv')\n",
    "\n",
    "# politifact_real_manually_checked = pd.read_excel('processed-data/scraped_text_filtered/politifact_real_manually_checked.xlsx', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gossipcop_fake = pd.read_csv('fakenewsnet/gossipcop_fake.csv')\n",
    "# filtered_g_fake = pd.read_csv('processed-data/scraped_text/gossipcop_fake_with_scraped_text.csv')\n",
    "\n",
    "gossipcop_real = pd.read_csv('fakenewsnet/gossipcop_real.csv')\n",
    "# filtered_g_real = pd.read_csv('processed-data/scraped_text/gossipcop_real_with_scraped_text.csv')"
   ]
  },
  {
   "source": [
    "### 3. Fetching the original article for the real news in the politifact dataset"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/624 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9aee05212bcc4aa78f1a2dc6155cb6eb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "302\n",
      "301\n",
      "no response\n",
      "301\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "303\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "406\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "no response\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "301\n",
      "no response\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "no response\n",
      "301\n",
      "301\n",
      "no response\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "404\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "302\n",
      "302\n",
      "no response\n",
      "301\n",
      "301\n",
      "no response\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "no response\n",
      "no response\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "no response\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "302\n",
      "302\n",
      "301\n",
      "301\n",
      "302\n",
      "no response\n",
      "301\n",
      "302\n",
      "301\n",
      "302\n",
      "no response\n",
      "301\n",
      "301\n",
      "302\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "404\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "302\n",
      "302\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "302\n",
      "404\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "406\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "302\n",
      "302\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "302\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "no response\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "no response\n",
      "301\n",
      "301\n",
      "301\n",
      "307\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "303\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "302\n",
      "301\n",
      "no response\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "no response\n",
      "no response\n",
      "301\n",
      "301\n",
      "301\n",
      "no response\n",
      "no response\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "no response\n",
      "301\n",
      "301\n"
     ]
    }
   ],
   "source": [
    "if 'text' not in politifact_real:\n",
    "    politifact_real['text'] = ''\n",
    "for index, url in enumerate(tqdm(politifact_real['news_url'])):\n",
    "    if politifact_real['text'].iloc[index] == '':\n",
    "        if type(url) != float:\n",
    "            if urlparse(url).scheme:\n",
    "                if politifact_real['text'].iloc[index] == '':\n",
    "                    politifact_real['text'].iloc[index] = process_url(url)"
   ]
  },
  {
   "source": [
    "### 4. Fetching the original article for the fake news in the politifact dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/432 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a4f2e5ff33b04f7cbc13211ec1b449e7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "301\n",
      "301\n",
      "404\n",
      "303\n",
      "301\n",
      "404\n",
      "301\n",
      "no response\n",
      "302\n",
      "301\n",
      "404\n",
      "no response\n",
      "302\n",
      "301\n",
      "404\n",
      "301\n",
      "406\n",
      "301\n",
      "no response\n",
      "301\n",
      "301\n",
      "404\n",
      "no response\n",
      "301\n",
      "no response\n",
      "no response\n",
      "no response\n",
      "302\n",
      "no response\n",
      "404\n",
      "404\n",
      "no response\n",
      "404\n",
      "406\n",
      "no response\n",
      "no response\n",
      "301\n",
      "no response\n",
      "no response\n",
      "404\n",
      "301\n",
      "404\n",
      "301\n",
      "301\n",
      "302\n",
      "no response\n",
      "301\n",
      "302\n",
      "301\n",
      "301\n",
      "404\n",
      "301\n",
      "301\n",
      "no response\n",
      "301\n",
      "no response\n",
      "404\n",
      "301\n",
      "no response\n",
      "no response\n",
      "302\n",
      "302\n",
      "302\n",
      "302\n",
      "301\n",
      "no response\n",
      "301\n",
      "404\n",
      "301\n",
      "no response\n",
      "404\n",
      "302\n",
      "no response\n",
      "404\n",
      "301\n",
      "303\n",
      "404\n",
      "no response\n",
      "301\n",
      "302\n",
      "no response\n",
      "301\n",
      "301\n",
      "no response\n",
      "404\n",
      "301\n",
      "301\n",
      "301\n",
      "406\n",
      "301\n",
      "no response\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "404\n",
      "301\n",
      "no response\n",
      "no response\n",
      "301\n",
      "404\n",
      "no response\n",
      "301\n",
      "no response\n",
      "301\n",
      "no response\n",
      "404\n",
      "400\n",
      "302\n",
      "301\n",
      "no response\n",
      "302\n",
      "404\n",
      "404\n",
      "302\n",
      "no response\n",
      "301\n",
      "301\n",
      "no response\n",
      "301\n",
      "301\n",
      "no response\n",
      "301\n",
      "404\n",
      "301\n",
      "303\n",
      "301\n",
      "301\n",
      "no response\n",
      "301\n",
      "no response\n",
      "302\n",
      "404\n",
      "no response\n",
      "302\n",
      "302\n",
      "301\n",
      "no response\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "404\n",
      "no response\n",
      "302\n",
      "301\n",
      "301\n",
      "no response\n",
      "301\n",
      "406\n",
      "301\n",
      "301\n",
      "no response\n",
      "404\n",
      "404\n",
      "301\n",
      "302\n",
      "404\n",
      "301\n",
      "404\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "406\n",
      "no response\n",
      "404\n",
      "301\n",
      "no response\n",
      "301\n",
      "no response\n",
      "301\n",
      "no response\n",
      "301\n",
      "404\n",
      "301\n",
      "301\n",
      "no response\n",
      "404\n",
      "301\n",
      "301\n",
      "no response\n",
      "301\n",
      "no response\n",
      "no response\n",
      "301\n",
      "no response\n",
      "301\n",
      "404\n",
      "404\n",
      "301\n",
      "no response\n",
      "no response\n",
      "301\n",
      "429\n",
      "no response\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if 'text' not in politifact_fake:\n",
    "    politifact_fake['text'] = ''\n",
    "for index, url in enumerate(tqdm(politifact_fake['news_url'])):\n",
    "    if politifact_fake['text'].iloc[index] == '':\n",
    "        if type(url) != float:\n",
    "            if urlparse(url).scheme:\n",
    "                if politifact_fake['text'].iloc[index] == '':\n",
    "                    politifact_fake['text'].iloc[index] = process_url(url)"
   ]
  },
  {
   "source": [
    "### 5. Fetching the original article for the real news in the gossipcop dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'text' not in gossipcop_real:\n",
    "    gossipcop_real['text'] = ''\n",
    "for index, url in enumerate(tqdm(gossipcop_real['news_url'])):\n",
    "    if gossipcop_real['text'].iloc[index] == '':\n",
    "        if type(url) != float:\n",
    "           if urlparse(url).scheme:\n",
    "                if gossipcop_real['text'].iloc[index] == '':\n",
    "                    gossipcop_real['text'].iloc[index] = process_url(url)\n",
    "                elif \"://\" in url: \n",
    "                    if gossipcop_real['text'].iloc[index] == '':\n",
    "                        gossipcop_real['text'].iloc[index] = process_url(url)\n",
    "                else: \n",
    "                    url = \"http://\" + url\n",
    "                    if gossipcop_real['text'].iloc[index] == '':\n",
    "                        gossipcop_real['text'].iloc[index] = process_url(url)"
   ]
  },
  {
   "source": [
    "### 6. Fetching the original article for the fake news in the gossipcop dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'text' not in gossipcop_fake:\n",
    "    gossipcop_fake['text'] = ''\n",
    "for index, url in enumerate(tqdm(gossipcop_fake['news_url'])):\n",
    "    if gossipcop_fake['text'].iloc[index] == '' and index > 2650:\n",
    "        if type(url) != float:\n",
    "            if \"://\" in url: \n",
    "                gossipcop_fake['text'].iloc[index] = process_url(url)\n",
    "            else:\n",
    "                url = \"http://\" + url\n",
    "                gossipcop_fake['text'].iloc[index] = process_url(url)"
   ]
  },
  {
   "source": [
    "### 7. In some cases, especially for fake news, the article has been removed from the internet and the text is therefore not available. Filter out these instances and drop the rows as topic modelling will not be applicable here"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_g_fake = gossipcop_fake[gossipcop_fake['text'] != '' ]\n",
    "filtered_g_fake = filtered_g_fake[filtered_g_fake['text'].notnull()]\n",
    "filtered_g_fake = filtered_g_fake[filtered_g_fake['tweet_ids'].notnull()]\n",
    "# filtered_g_fake.to_csv('processed-data/scraped_text/gossipcop_fake_with_scraped_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_g_real = gossipcop_real[gossipcop_real['text'] != '' ]\n",
    "filtered_g_real = filtered_g_real[filtered_g_real['text'].notnull()]\n",
    "filtered_g_real = filtered_g_real[filtered_g_real['tweet_ids'].notnull()]\n",
    "# filtered_g_real.to_csv('processed-data/scraped_text/gossipcop_real_with_scraped_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_p_fake = politifact_fake[politifact_fake['text'] != '' ]\n",
    "filtered_p_fake = filtered_p_fake[filtered_p_fake['text'].notnull()]\n",
    "filtered_p_fake = filtered_p_fake[filtered_p_fake['tweet_ids'].notnull()]\n",
    "# filtered_p_fake.to_csv('processed-data/scraped_text/politifact_fake_with_scraped_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_p_real = politifact_real[politifact_real['text'] != '' ]\n",
    "filtered_p_real = filtered_p_real[filtered_p_real['text'].notnull()]\n",
    "filtered_p_real = filtered_p_real[filtered_p_real['tweet_ids'].notnull()]\n",
    "# filtered_p_real.to_csv('processed-data/scraped_text/politifact_real_with_scraped_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_p_real = pd.read_csv('processed-data/scraped_text_filtered/politifact_real_manually_checked.csv')"
   ]
  },
  {
   "source": [
    "### 8. Tweet processing\n",
    "\n",
    "- `filtered_p_real` and `filtered_p_fake` contain a column of `tweet_ids`.\n",
    "- The Twitter v2 [API](https://developer.twitter.com/en/docs/twitter-api/tweets/lookup/api-reference/get-tweets) for tweets allows queries of up to 100 tweets at a time\n",
    "1. Loop through the dataframe\n",
    "2. Add at most 100 tweet_ids to a list and construct the request object\n",
    "3. EAFP, catch the exception for when we reach the 300 requests per 15 minutes limit and wait for 15 minutes with `time.sleep(900)`\n",
    "4. Process the response and construct an object with the data of interest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                        id                                           news_url  \\\n",
       "0     gossipcop-2493749932  www.dailymail.co.uk/tvshowbiz/article-5874213/...   \n",
       "1     gossipcop-4580247171  hollywoodlife.com/2018/05/05/paris-jackson-car...   \n",
       "2      gossipcop-941805037  variety.com/2017/biz/news/tax-march-donald-tru...   \n",
       "3     gossipcop-2547891536  www.dailymail.co.uk/femail/article-3499192/Do-...   \n",
       "4     gossipcop-5476631226  variety.com/2018/film/news/list-2018-oscar-nom...   \n",
       "...                    ...                                                ...   \n",
       "5318  gossipcop-6702260693  www.huffingtonpost.com/2012/09/11/september-11...   \n",
       "5319  gossipcop-6051845337  www.dailymail.co.uk/news/article-4915674/NASCA...   \n",
       "5320  gossipcop-2435526162  www.telegraph.co.uk/men/the-filter/7-signs-dav...   \n",
       "5321  gossipcop-4576152851  www.vanityfair.com/style/2016/09/ryan-gosling-...   \n",
       "5322   gossipcop-919334865  www.lifeandstylemag.com/posts/jamie-foxx-katie...   \n",
       "\n",
       "                                                  title  \\\n",
       "0     Did Miley Cyrus and Liam Hemsworth secretly ge...   \n",
       "1     Paris Jackson & Cara Delevingne Enjoy Night Ou...   \n",
       "2     Celebrities Join Tax March in Protest of Donal...   \n",
       "3     Cindy Crawford's daughter Kaia Gerber wears a ...   \n",
       "4         Full List of 2018 Oscar Nominations – Variety   \n",
       "...                                                 ...   \n",
       "5318   September 11: Celebrities Remember 9/11 (TWEETS)   \n",
       "5319  NASCAR owners threaten to fire drivers who pro...   \n",
       "5320  The 7 signs that David Beckham is definitely h...   \n",
       "5321  Ryan Gosling and Eva Mendes Did Not Get Marrie...   \n",
       "5322  Jamie Foxx Spends the Day With Katie Holmes an...   \n",
       "\n",
       "                                              tweet_ids text  \n",
       "0     284329075902926848\\t284332744559968256\\t284335...       \n",
       "1     992895508267130880\\t992897935418503169\\t992899...       \n",
       "2     853359353532829696\\t853359576543920128\\t853359...       \n",
       "3     988821905196158981\\t988824206556172288\\t988825...       \n",
       "4     955792793632432131\\t955795063925301249\\t955798...       \n",
       "...                                                 ...  ...  \n",
       "5318                                 245643768638894080       \n",
       "5319  912048333413330944\\t912048571482087424\\t912049...       \n",
       "5320  897794716447539200\\t897804460830928896\\t897842...       \n",
       "5321  778678901572710400\\t778681718714740736\\t778683...       \n",
       "5322  913137595424608258\\t913139996059717632\\t913146...       \n",
       "\n",
       "[5323 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>news_url</th>\n      <th>title</th>\n      <th>tweet_ids</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>gossipcop-2493749932</td>\n      <td>www.dailymail.co.uk/tvshowbiz/article-5874213/...</td>\n      <td>Did Miley Cyrus and Liam Hemsworth secretly ge...</td>\n      <td>284329075902926848\\t284332744559968256\\t284335...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>gossipcop-4580247171</td>\n      <td>hollywoodlife.com/2018/05/05/paris-jackson-car...</td>\n      <td>Paris Jackson &amp; Cara Delevingne Enjoy Night Ou...</td>\n      <td>992895508267130880\\t992897935418503169\\t992899...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>gossipcop-941805037</td>\n      <td>variety.com/2017/biz/news/tax-march-donald-tru...</td>\n      <td>Celebrities Join Tax March in Protest of Donal...</td>\n      <td>853359353532829696\\t853359576543920128\\t853359...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>gossipcop-2547891536</td>\n      <td>www.dailymail.co.uk/femail/article-3499192/Do-...</td>\n      <td>Cindy Crawford's daughter Kaia Gerber wears a ...</td>\n      <td>988821905196158981\\t988824206556172288\\t988825...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>gossipcop-5476631226</td>\n      <td>variety.com/2018/film/news/list-2018-oscar-nom...</td>\n      <td>Full List of 2018 Oscar Nominations – Variety</td>\n      <td>955792793632432131\\t955795063925301249\\t955798...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5318</th>\n      <td>gossipcop-6702260693</td>\n      <td>www.huffingtonpost.com/2012/09/11/september-11...</td>\n      <td>September 11: Celebrities Remember 9/11 (TWEETS)</td>\n      <td>245643768638894080</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>5319</th>\n      <td>gossipcop-6051845337</td>\n      <td>www.dailymail.co.uk/news/article-4915674/NASCA...</td>\n      <td>NASCAR owners threaten to fire drivers who pro...</td>\n      <td>912048333413330944\\t912048571482087424\\t912049...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>5320</th>\n      <td>gossipcop-2435526162</td>\n      <td>www.telegraph.co.uk/men/the-filter/7-signs-dav...</td>\n      <td>The 7 signs that David Beckham is definitely h...</td>\n      <td>897794716447539200\\t897804460830928896\\t897842...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>5321</th>\n      <td>gossipcop-4576152851</td>\n      <td>www.vanityfair.com/style/2016/09/ryan-gosling-...</td>\n      <td>Ryan Gosling and Eva Mendes Did Not Get Marrie...</td>\n      <td>778678901572710400\\t778681718714740736\\t778683...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>5322</th>\n      <td>gossipcop-919334865</td>\n      <td>www.lifeandstylemag.com/posts/jamie-foxx-katie...</td>\n      <td>Jamie Foxx Spends the Day With Katie Holmes an...</td>\n      <td>913137595424608258\\t913139996059717632\\t913146...</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n<p>5323 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "gossipcop_fake"
   ]
  },
  {
   "source": [
    "politifact_real_tweet_data = []\n",
    "politifact_real_tweet_dataframe = pd.DataFrame(columns=['news_id'])\n",
    "rt_obj = {}\n",
    "response_count = 0\n",
    "try:\n",
    "    politifact_real_tweet_dataframe\n",
    "except NameError:\n",
    "    print('Creating new dataframe for real tweets')\n",
    "else:\n",
    "    politifact_real_tweet_dataframe = pd.DataFrame(columns=['news_id'])\n",
    "for index, tweet_ids in enumerate(tqdm(politifact_real['tweet_ids'])):\n",
    "    if type(tweet_ids) != float:\n",
    "        tweet_id_list = tweet_ids.split()\n",
    "        # print(tweet_id_list)\n",
    "        temp_data_for_author = []\n",
    "        # print(index % 100)\n",
    "        temp_list_of_100 = ''\n",
    "        # print(len(tweet_id_list))\n",
    "        for tweet_index, tweet_id in enumerate(tweet_id_list):\n",
    "            if tweet_index % 100 == 0 and tweet_index > 0:\n",
    "                if temp_list_of_100.endswith(','):\n",
    "                    temp_list_of_100 = temp_list_of_100[:-1]\n",
    "                try:\n",
    "                        response = requests.get(f'https://api.twitter.com/2/tweets?ids={temp_list_of_100}&tweet.fields=created_at,author_id&expansions=referenced_tweets.id',  headers=headers)\n",
    "                except (ConnectionError, exceptions.RequestException) as e:\n",
    "                    print(e)\n",
    "                    time.sleep(900)\n",
    "                    index-=1;\n",
    "                temp_list_of_100 = ''\n",
    "                \n",
    "                try:\n",
    "                    data = response.json()\n",
    "                except JSONDecodeError as e:\n",
    "                    continue\n",
    "                if 'data' in data:\n",
    "                    for item in data['data']:\n",
    "                        if 'created_at' in item:\n",
    "                            item['news_id'] = politifact_real.iloc[index]['id']\n",
    "                            if politifact_real.iloc[index]['id'] not in politifact_real['id'].to_list():\n",
    "                                politifact_real_tweet_data.append(item)\n",
    "                        if 'referenced_tweets' in item:\n",
    "                            for rt in item['referenced_tweets']:\n",
    "                                try:\n",
    "                                    rt_obj[politifact_real.iloc[index]['id']].append(rt)\n",
    "                                except KeyError:\n",
    "                                    rt_obj[politifact_real.iloc[index]['id']] = [rt]\n",
    "                                \n",
    "            elif tweet_index % 100 == 99:\n",
    "                temp_list_of_100 = temp_list_of_100 + f'{tweet_id},'\n",
    "            # same if it's the last of the batch we process\n",
    "            elif tweet_index == len(politifact_real['tweet_ids'])-1:\n",
    "                temp_list_of_100 = temp_list_of_100 + f'{tweet_id},'\n",
    "            # otherwise we got to separate with a comma\n",
    "            else:\n",
    "                temp_list_of_100 = temp_list_of_100 + f'{tweet_id},'"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 31,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/624 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b49677a11ef74e7e90d7faa741d215cb"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "politifact_real_tweet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/432 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bcea1c9c45384f5fa26c7c210c2a1a7b"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "politifact_fake_tweet_data = []\n",
    "politifact_fake_tweet_dataframe = pd.DataFrame(columns=['news_id'])\n",
    "\n",
    "try:\n",
    "    politifact_fake_tweet_dataframe\n",
    "except NameError:\n",
    "    print('Creating new dataframe for fake tweets')\n",
    "else:\n",
    "    politifact_fake_tweet_dataframe = pd.DataFrame(columns=['news_id'])\n",
    "for index, tweet_ids in enumerate(tqdm(politifact_fake['tweet_ids'])):\n",
    "    if type(tweet_ids) != float:\n",
    "        tweet_id_list = tweet_ids.split()\n",
    "        temp_data_for_author = []\n",
    "        temp_list_of_100 = ''\n",
    "        for tweet_index, tweet_id in enumerate(tweet_id_list):\n",
    "            if tweet_index % 100 == 0 and tweet_index > 0:\n",
    "                if temp_list_of_100.endswith(','):\n",
    "                    temp_list_of_100 = temp_list_of_100[:-1]\n",
    "                try:\n",
    "                        response = requests.get(f'https://api.twitter.com/2/tweets?ids={temp_list_of_100}&tweet.fields=created_at,author_id',  headers=headers)\n",
    "                except (ConnectionError, exceptions.RequestException) as e:\n",
    "                    print(e)\n",
    "                    time.sleep(900)\n",
    "                    index-=1;\n",
    "                temp_list_of_100 = ''\n",
    "                try:\n",
    "                    data = response.json()\n",
    "                except JSONDecodeError as e:\n",
    "                    continue\n",
    "                if 'data' in data:\n",
    "                    for item in data['data']:\n",
    "                        if 'created_at' in item:\n",
    "                            item['news_id'] = politifact_fake.iloc[index]['id']\n",
    "                            if politifact_fake.iloc[index]['id'] not in politifact_fake_tweet_dataframe['news_id'].to_list():\n",
    "                                politifact_fake_tweet_data.append(item)\n",
    "               \n",
    "            elif tweet_index % 100 == 99:\n",
    "                temp_list_of_100 = temp_list_of_100 + f'{tweet_id},'\n",
    "            # same if it's the last of the batch we process\n",
    "            elif tweet_index == len(politifact_fake['tweet_ids'])-1:\n",
    "                temp_list_of_100 = temp_list_of_100 + f'{tweet_id},'\n",
    "            # otherwise we got to separate with a comma\n",
    "            else:\n",
    "                temp_list_of_100 = temp_list_of_100 + f'{tweet_id},'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "source": [
    "politifact_real_tweet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "politifact_fake_df = pd.DataFrame(politifact_fake_tweet_data)\n",
    "politifact_fake_df = politifact_fake_df.drop_duplicates(subset=['news_id','author_id'])\n",
    "politifact_fake_author_counts = politifact_fake_df['author_id'].value_counts()\n",
    "politifact_fake_counts = pd.DataFrame()\n",
    "politifact_fake_counts['fake'] = politifact_real_author_counts\n",
    "politifact_fake_counts['author_id'] = politifact_counts.index\n",
    "politifact_real_df = pd.DataFrame(politifact_real_tweet_data)\n",
    "politifact_real_df = politifact_real_df.drop_duplicates(subset=['news_id','author_id'])\n",
    "politifact_real_author_counts = politifact_real_df['author_id'].value_counts()\n",
    "politifact_counts['real'] = politifact_fake_author_counts\n",
    "politifact_counts_merged = politifact_counts.merge(politifact_fake_counts, on=\"author_id\", how = 'inner')\n",
    "# politifact_counts_merged = politifact_counts_merged.reset_index()\n",
    "# politifact_counts_merged.to_csv('processed-data/tweet_counts_by_author_politifact.csv')"
   ]
  },
  {
   "source": [
    "### 9. The authors with the number of fake and real tweets they shared"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        real           author_id  fake\n",
       "0        8.0            48470839    36\n",
       "1        4.0            34383891    29\n",
       "2       17.0          1179710990    27\n",
       "3        2.0           369760961    24\n",
       "4        1.0            15523710    21\n",
       "...      ...                 ...   ...\n",
       "148184   NaN          2816232049     1\n",
       "148185   NaN          2376305339     1\n",
       "148186   1.0  794150830446440448     1\n",
       "148187   NaN            84431570     1\n",
       "148188   NaN            19378586     1\n",
       "\n",
       "[148189 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>real</th>\n      <th>author_id</th>\n      <th>fake</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8.0</td>\n      <td>48470839</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.0</td>\n      <td>34383891</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>17.0</td>\n      <td>1179710990</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.0</td>\n      <td>369760961</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>15523710</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>148184</th>\n      <td>NaN</td>\n      <td>2816232049</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>148185</th>\n      <td>NaN</td>\n      <td>2376305339</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>148186</th>\n      <td>1.0</td>\n      <td>794150830446440448</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>148187</th>\n      <td>NaN</td>\n      <td>84431570</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>148188</th>\n      <td>NaN</td>\n      <td>19378586</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>148189 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "source": [
    "politifact_counts_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tweets_by_author = pd.DataFrame(columns=[\"author_id\", \"tweets\", \"real_count\", \"fake_count\"])\n",
    "\n",
    "# for index, item in enumerate(politifact_real_tweet_data):\n",
    "#     if 'author_id' in item:\n",
    "#         if tweets_by_author['author_id'].str.contains(item['author_id']).any():\n",
    "#             try:\n",
    "#                 current_index = tweets_by_author.index[tweets_by_author.author_id == item['author_id']].tolist()[0]\n",
    "#                 tweets_by_author.loc[current_index, 'real_count'] += 1\n",
    "#             except IndexError as e:\n",
    "#                 print(e)\n",
    "#         else: \n",
    "#             tweets_by_author = tweets_by_author.append({'author_id':item['author_id'],'real_count':1, 'fake_count':0}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweet_times_p_real = pd.DataFrame(columns=[\"id\", \"timestamps\"])\n",
    "for index, item in enumerate(politifact_real_tweet_data):\n",
    "    for k in item:\n",
    "        for item_index, j in enumerate(item[k]):\n",
    "            if 'id' in j:\n",
    "                if tweet_times_p_real['id'].str.contains(j['id']).any():\n",
    "                    try:\n",
    "                        current_index = tweet_times_p_real.index[tweet_times_p_real.id == j['id']].to_list()[0]\n",
    "                        created_at = j['created_at']\n",
    "                        tweet_times_p_real.loc[current_index, 'timestamps'] += f',{created_at}' \n",
    "                    except IndexError as e:\n",
    "                        print(e)\n",
    "                else:\n",
    "                    tweet_times_p_real = tweet_times_p_real.append({'id':j['id'], 'timestamps':j['created_at']}, ignore_index=True)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_times_p_fake = pd.DataFrame(columns=[\"id\", \"timestamps\"])\n",
    "for index, item in enumerate(politifact_fake_tweet_data):\n",
    "    for k in item:\n",
    "        for item_index, j in enumerate(item[k]):\n",
    "            if 'id' in j:\n",
    "                if tweet_times_p_fake['id'].str.contains(j['id']).any():\n",
    "                    try:\n",
    "                        current_index = tweet_times_p_fake.index[tweet_times_p_fake.id == j['id']].to_list()[0]\n",
    "                        tweet_times_p_fake.loc[current_index, 'timestamps'] += j['created_at']\n",
    "                    except IndexError as e:\n",
    "                        print(e)\n",
    "                else:\n",
    "                    tweet_times_p_fake = tweet_times_p_fake.append({'id':j['id'], 'timestamps':j['created_at']}, ignore_index=True)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_times_g_fake = pd.DataFrame(columns=[\"id\", \"timestamps\"])\n",
    "for index, item in enumerate(politifact_fake_tweet_data):\n",
    "    for k in item:\n",
    "        for item_index, j in enumerate(item[k]):\n",
    "            if 'id' in j:\n",
    "                if tweet_times_p_fake['id'].str.contains(j['id']).any():\n",
    "                    try:\n",
    "                        current_index = tweet_times_p_fake.index[tweet_times_p_fake.id == j['id']].to_list()[0]\n",
    "                        tweet_times_p_fake.loc[current_index, 'timestamps'] += j['created_at']\n",
    "                    except IndexError as e:\n",
    "                        print(e)\n",
    "                else:\n",
    "                    tweet_times_p_fake = tweet_times_p_fake.append({'id':j['id'], 'timestamps':j['created_at']}, ignore_index=True)\n",
    "           "
   ]
  },
  {
   "source": [
    "### Politifact fake processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Unnamed: 0               id  \\\n",
       "0             3  politifact14355   \n",
       "1             4  politifact15371   \n",
       "3             7  politifact14795   \n",
       "4             8  politifact14328   \n",
       "5             9  politifact13775   \n",
       "..          ...              ...   \n",
       "228         419  politifact14169   \n",
       "229         421  politifact14992   \n",
       "230         422  politifact14158   \n",
       "231         427  politifact14944   \n",
       "232         428  politifact14071   \n",
       "\n",
       "                                              news_url  \\\n",
       "0    https://howafrica.com/oscar-pistorius-attempts...   \n",
       "1    http://washingtonsources.org/trump-votes-for-d...   \n",
       "3    https://web.archive.org/web/20171027105356/htt...   \n",
       "4    https://web.archive.org/web/20170702174006/htt...   \n",
       "5    http://beforeitsnews.com/opinion-conservative/...   \n",
       "..                                                 ...   \n",
       "228  https://web.archive.org/web/20170528095037/htt...   \n",
       "229  http://www.trainnews.info/2018/01/rep-paul-gos...   \n",
       "230  https://web.archive.org/web/20170602190500/htt...   \n",
       "231  http://thehill.com/homenews/senate/369928-who-...   \n",
       "232  https://web.archive.org/web/20170322070001/htt...   \n",
       "\n",
       "                                                 title  \\\n",
       "0           Oscar Pistorius Attempts To Commit Suicide   \n",
       "1          Trump Votes For Death Penalty For Being Gay   \n",
       "3    Saudi Arabia to Behead 6 School Girls for Bein...   \n",
       "4    Malia Obama Fired From Cushy Internship At Spa...   \n",
       "5             Target to Discontinue Sale of Holy Bible   \n",
       "..                                                 ...   \n",
       "228  Rubio: “Rape Victims Should Be In Custody If T...   \n",
       "229  Rep. Paul Gosar Asks Capitol Police to Arrest ...   \n",
       "230  WORSE THAN HITLER! Trey Gowdy’s Son Found In A...   \n",
       "231        Who is affected by the government shutdown?   \n",
       "232  Lindsey Graham Threatens To Convert To Democra...   \n",
       "\n",
       "                                             tweet_ids  \\\n",
       "0    886941526458347521\\t887011300278194176\\t887023...   \n",
       "1    915205698212040704\\t915242076681506816\\t915249...   \n",
       "3    923126512458616832\\t923135295070990341\\t923189...   \n",
       "4    880455776107679747\\t880457763876462598\\t880461...   \n",
       "5    732741826084397057\\t732741823534227456\\t732741...   \n",
       "..                                                 ...   \n",
       "228  663538460104392704\\t663757208031780864\\t663764...   \n",
       "229  958425300144218112\\t958428242528145409\\t958428...   \n",
       "230                                 865933040492703745   \n",
       "231  954602090462146560\\t954602093171609600\\t954650...   \n",
       "232  740351669834244096\\t740391312277573632\\t740474...   \n",
       "\n",
       "                                                  text  \n",
       "0                                    Home  Advertis...  \n",
       "1                       Washington Sources         ...  \n",
       "3                  success  fail                   ...  \n",
       "4                     success  fail                ...  \n",
       "5                             You're using an Ad-Bl...  \n",
       "..                                                 ...  \n",
       "228             success  fail                      ...  \n",
       "229      Home Business Online Business Bitcoin Revi...  \n",
       "230                success  fail                   ...  \n",
       "231                                                ...  \n",
       "232                           success  fail        ...  \n",
       "\n",
       "[205 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>news_url</th>\n      <th>title</th>\n      <th>tweet_ids</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>politifact14355</td>\n      <td>https://howafrica.com/oscar-pistorius-attempts...</td>\n      <td>Oscar Pistorius Attempts To Commit Suicide</td>\n      <td>886941526458347521\\t887011300278194176\\t887023...</td>\n      <td>Home  Advertis...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>politifact15371</td>\n      <td>http://washingtonsources.org/trump-votes-for-d...</td>\n      <td>Trump Votes For Death Penalty For Being Gay</td>\n      <td>915205698212040704\\t915242076681506816\\t915249...</td>\n      <td>Washington Sources         ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>politifact14795</td>\n      <td>https://web.archive.org/web/20171027105356/htt...</td>\n      <td>Saudi Arabia to Behead 6 School Girls for Bein...</td>\n      <td>923126512458616832\\t923135295070990341\\t923189...</td>\n      <td>success  fail                   ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8</td>\n      <td>politifact14328</td>\n      <td>https://web.archive.org/web/20170702174006/htt...</td>\n      <td>Malia Obama Fired From Cushy Internship At Spa...</td>\n      <td>880455776107679747\\t880457763876462598\\t880461...</td>\n      <td>success  fail                ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>9</td>\n      <td>politifact13775</td>\n      <td>http://beforeitsnews.com/opinion-conservative/...</td>\n      <td>Target to Discontinue Sale of Holy Bible</td>\n      <td>732741826084397057\\t732741823534227456\\t732741...</td>\n      <td>You're using an Ad-Bl...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>228</th>\n      <td>419</td>\n      <td>politifact14169</td>\n      <td>https://web.archive.org/web/20170528095037/htt...</td>\n      <td>Rubio: “Rape Victims Should Be In Custody If T...</td>\n      <td>663538460104392704\\t663757208031780864\\t663764...</td>\n      <td>success  fail                      ...</td>\n    </tr>\n    <tr>\n      <th>229</th>\n      <td>421</td>\n      <td>politifact14992</td>\n      <td>http://www.trainnews.info/2018/01/rep-paul-gos...</td>\n      <td>Rep. Paul Gosar Asks Capitol Police to Arrest ...</td>\n      <td>958425300144218112\\t958428242528145409\\t958428...</td>\n      <td>Home Business Online Business Bitcoin Revi...</td>\n    </tr>\n    <tr>\n      <th>230</th>\n      <td>422</td>\n      <td>politifact14158</td>\n      <td>https://web.archive.org/web/20170602190500/htt...</td>\n      <td>WORSE THAN HITLER! Trey Gowdy’s Son Found In A...</td>\n      <td>865933040492703745</td>\n      <td>success  fail                   ...</td>\n    </tr>\n    <tr>\n      <th>231</th>\n      <td>427</td>\n      <td>politifact14944</td>\n      <td>http://thehill.com/homenews/senate/369928-who-...</td>\n      <td>Who is affected by the government shutdown?</td>\n      <td>954602090462146560\\t954602093171609600\\t954650...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>232</th>\n      <td>428</td>\n      <td>politifact14071</td>\n      <td>https://web.archive.org/web/20170322070001/htt...</td>\n      <td>Lindsey Graham Threatens To Convert To Democra...</td>\n      <td>740351669834244096\\t740391312277573632\\t740474...</td>\n      <td>success  fail        ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>205 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "filtered_p_fake = filtered_p_fake[filtered_p_fake['tweet_ids'].notnull()]\n",
    "filtered_p_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/91 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8cba73d254434815b5c079a6929642fc"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "politifact_fake_tweet_times = pd.DataFrame(columns=['news_id', 'timestamps'])\n",
    "politifact_fake_tweet_data = []\n",
    "\n",
    "# for index, tweet_ids in enumerate(tqdm(filtered_p_fake['tweet_ids'])):\n",
    "for index, tweet_ids in enumerate(tqdm(missing_filtered_p_fake['tweet_ids'])):\n",
    "    if type(tweet_ids) != float:\n",
    "        tweet_id_list = tweet_ids.split()\n",
    "        temp_data_for_author = []\n",
    "        temp_list_of_100 = ''\n",
    "        for tweet_index, tweet_id in enumerate(tweet_id_list):\n",
    "            if tweet_index % 100 == 0 and tweet_index > 0:\n",
    "                time.sleep(0.8)\n",
    "                if temp_list_of_100.endswith(','):\n",
    "                    temp_list_of_100 = temp_list_of_100[:-1]\n",
    "                    response = requests.get(f'https://api.twitter.com/2/tweets?ids={temp_list_of_100}&tweet.fields=created_at,author_id',  headers=headers) \n",
    "                    temp_list_of_100 = ''\n",
    "                else:\n",
    "                    response = requests.get(f'https://api.twitter.com/2/tweets?ids={temp_list_of_100}&tweet.fields=created_at,author_id',  headers=headers) \n",
    "                    temp_list_of_100 = ''\n",
    "                try:\n",
    "                    data = response.json()\n",
    "                    # print(response)\n",
    "                    # print(data)\n",
    "                except JSONDecodeError as e:\n",
    "                    continue\n",
    "                if 'data' in data:\n",
    "                    for item in data['data']:\n",
    "                        if 'created_at' in item:\n",
    "                            item['news_id'] = filtered_p_fake.iloc[index]['id']\n",
    "                            if filtered_p_fake.iloc[index]['id'] not in politifact_fake_tweet_dataframe['news_id'].to_list():\n",
    "                                print(filtered_p_fake.iloc[index]['id'])\n",
    "                                politifact_fake_tweet_data.append(item)\n",
    "                    # print(len(data['data']))\n",
    "                    # print(tweet_index)\n",
    "                    # print(index)\n",
    "                    # for tweet in data['data']:\n",
    "                    #     # print(filtered_p_fake.loc[index, 'id'])\n",
    "                    #     if politifact_fake_tweet_times['news_id'].str.contains(filtered_p_fake.loc[index, 'id']).any():\n",
    "                    #         try:\n",
    "                    #             current_index = politifact_fake_tweet_times.index[politifact_fake_tweet_times.news_id == filtered_p_fake.loc[index, 'id']].tolist()[0]\n",
    "                    #             # print(current_index)\n",
    "                    #             created_at = tweet['created_at']\n",
    "                    #             politifact_fake_tweet_times.loc[current_index, 'timestamps'] += f',{created_at}' \n",
    "                    #         except IndexError as e:\n",
    "                    #             print(e)\n",
    "                    #     else: \n",
    "                    #         politifact_fake_tweet_times = politifact_fake_tweet_times.append({'news_id':filtered_p_fake.loc[index, 'id'], 'timestamps':tweet['created_at']}, ignore_index=True)\n",
    "                    #         # print(tweet.created_at)\n",
    "                    #         # print(data['data'][index]['created_at'])\n",
    "                    #         # print('piece_of_news ', filtered_p_fake.loc[index, 'id'])\n",
    "\n",
    "            elif tweet_index % 100 == 99:\n",
    "                temp_list_of_100 = temp_list_of_100 + f'{tweet_id},'\n",
    "            # same if it's the last of the batch we process\n",
    "            elif tweet_index == len(filtered_p_fake['tweet_ids'])-1:\n",
    "                temp_list_of_100 = temp_list_of_100 + f'{tweet_id},'\n",
    "            # otherwise we got to separate with a comma\n",
    "            else:\n",
    "                temp_list_of_100 = temp_list_of_100 + f'{tweet_id},'\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/366 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "27de6924267c40aeabc9cd207b4e4be9"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "politifact_real_tweet_times = pd.DataFrame(columns=['news_id', 'timestamps'])\n",
    "politifact_real_tweet_data = []\n",
    "\n",
    "# for index, tweet_ids in enumerate(tqdm(filtered_p_fake['tweet_ids'])):\n",
    "for index, tweet_ids in enumerate(tqdm(filtered_p_real['tweet_ids'])):\n",
    "    if type(tweet_ids) != float:\n",
    "        tweet_id_list = tweet_ids.split()\n",
    "        temp_data_for_author = []\n",
    "        temp_list_of_100 = ''\n",
    "        for tweet_index, tweet_id in enumerate(tweet_id_list):\n",
    "            if tweet_index % 100 == 0 and tweet_index > 0:\n",
    "                time.sleep(0.8)\n",
    "                if temp_list_of_100.endswith(','):\n",
    "                    temp_list_of_100 = temp_list_of_100[:-1]\n",
    "                    response = requests.get(f'https://api.twitter.com/2/tweets?ids={temp_list_of_100}&tweet.fields=created_at,author_id',  headers=headers) \n",
    "                    temp_list_of_100 = ''\n",
    "                else:\n",
    "                    response = requests.get(f'https://api.twitter.com/2/tweets?ids={temp_list_of_100}&tweet.fields=created_at,author_id',  headers=headers) \n",
    "                    temp_list_of_100 = ''\n",
    "                try:\n",
    "                    data = response.json()\n",
    "                    # print(response)\n",
    "                    # print(data)\n",
    "                except JSONDecodeError as e:\n",
    "                    continue\n",
    "                if 'data' in data:\n",
    "                    for item in data['data']:\n",
    "                        if 'created_at' in item:\n",
    "                            item['news_id'] = filtered_p_real.iloc[index]['id']\n",
    "                            # if filtered_p_real.iloc[index]['id'] not in politifact_real_tweet_dataframe['news_id'].to_list():\n",
    "                                # print(filtered_p_fake.iloc[index]['id'])\n",
    "                            politifact_real_tweet_data.append(item)\n",
    "                    # print(len(data['data']))\n",
    "                    # print(tweet_index)\n",
    "                    # print(index)\n",
    "                    # for tweet in data['data']:\n",
    "                    #     # print(filtered_p_fake.loc[index, 'id'])\n",
    "                    #     if politifact_fake_tweet_times['news_id'].str.contains(filtered_p_fake.loc[index, 'id']).any():\n",
    "                    #         try:\n",
    "                    #             current_index = politifact_fake_tweet_times.index[politifact_fake_tweet_times.news_id == filtered_p_fake.loc[index, 'id']].tolist()[0]\n",
    "                    #             # print(current_index)\n",
    "                    #             created_at = tweet['created_at']\n",
    "                    #             politifact_fake_tweet_times.loc[current_index, 'timestamps'] += f',{created_at}' \n",
    "                    #         except IndexError as e:\n",
    "                    #             print(e)\n",
    "                    #     else: \n",
    "                    #         politifact_fake_tweet_times = politifact_fake_tweet_times.append({'news_id':filtered_p_fake.loc[index, 'id'], 'timestamps':tweet['created_at']}, ignore_index=True)\n",
    "                    #         # print(tweet.created_at)\n",
    "                    #         # print(data['data'][index]['created_at'])\n",
    "                    #         # print('piece_of_news ', filtered_p_fake.loc[index, 'id'])\n",
    "\n",
    "            elif tweet_index % 100 == 99:\n",
    "                temp_list_of_100 = temp_list_of_100 + f'{tweet_id},'\n",
    "            # same if it's the last of the batch we process\n",
    "            elif tweet_index == len(filtered_p_real['tweet_ids'])-1:\n",
    "                temp_list_of_100 = temp_list_of_100 + f'{tweet_id},'\n",
    "            # otherwise we got to separate with a comma\n",
    "            else:\n",
    "                temp_list_of_100 = temp_list_of_100 + f'{tweet_id},'\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "politifact_real_tweet_dataframe = pd.DataFrame(politifact_real_tweet_data)\n",
    "# politifact_real_tweet_dataframe = politifact_real_tweet_dataframe.append(politifact_real_tweet_data, ignore_index=True)\n",
    "politifact_real_tweet_dataframe.to_csv('processed-data/politifact_real_tweet_times.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "metadata": {},
     "execution_count": 184
    }
   ],
   "source": [
    "len(politifact_real_tweet_dataframe['news_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# politifact_fake_tweet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "politifact_fake_tweet_dataframe = politifact_fake_tweet_dataframe.append(politifact_fake_tweet_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "politifact_fake_tweet_dataframe.to_csv('processed-data/politifact_fake_tweet_times.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "78500"
      ]
     },
     "metadata": {},
     "execution_count": 162
    }
   ],
   "source": [
    "len(politifact_fake_tweet_dataframe['id'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_politifact = politifact_fake_tweet_dataframe['news_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_filtered_p_fake = filtered_p_fake[~filtered_p_fake['id'].isin(collected_politifact)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "politifact_fake_times = pd.DataFrame(columns=['id','timestamps'])\n",
    "for index, item in enumerate(politifact_fake_tweet_data):\n",
    "    for k in item:\n",
    "        for item_index, j in enumerate(item[k]):\n",
    "            if 'created_at' in j:\n",
    "                if politifact_fake_times['id'].str.contains(j['id']).any():\n",
    "                    try:\n",
    "                        current_index = politifact_fake_times.index[politifact_fake_times.id == j['id']].tolist()[0]\n",
    "                        politifact_fake_times.loc[current_index, 'timestamps'] += j['created_at']\n",
    "                    except IndexError as e:\n",
    "                        print(e)\n",
    "                else: \n",
    "                    politifact_fake_times = politifact_fake_times.append({'id':j['id'], 'timestamps':j['created_at']}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                        id                timestamps\n",
       "0       978246351036264453  2018-03-26T12:24:39.000Z\n",
       "1       978246559472275456  2018-03-26T12:25:29.000Z\n",
       "2       978246571128250368  2018-03-26T12:25:32.000Z\n",
       "3       978246651491094528  2018-03-26T12:25:51.000Z\n",
       "4       978247005481947136  2018-03-26T12:27:15.000Z\n",
       "...                    ...                       ...\n",
       "20947  1012345194983907328  2018-06-28T14:41:17.000Z\n",
       "20948  1012345247916003328  2018-06-28T14:41:30.000Z\n",
       "20949  1012345635062853634  2018-06-28T14:43:02.000Z\n",
       "20950  1012345706085011456  2018-06-28T14:43:19.000Z\n",
       "20951  1012345764033519616  2018-06-28T14:43:33.000Z\n",
       "\n",
       "[20952 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>timestamps</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>978246351036264453</td>\n      <td>2018-03-26T12:24:39.000Z</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>978246559472275456</td>\n      <td>2018-03-26T12:25:29.000Z</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>978246571128250368</td>\n      <td>2018-03-26T12:25:32.000Z</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>978246651491094528</td>\n      <td>2018-03-26T12:25:51.000Z</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>978247005481947136</td>\n      <td>2018-03-26T12:27:15.000Z</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20947</th>\n      <td>1012345194983907328</td>\n      <td>2018-06-28T14:41:17.000Z</td>\n    </tr>\n    <tr>\n      <th>20948</th>\n      <td>1012345247916003328</td>\n      <td>2018-06-28T14:41:30.000Z</td>\n    </tr>\n    <tr>\n      <th>20949</th>\n      <td>1012345635062853634</td>\n      <td>2018-06-28T14:43:02.000Z</td>\n    </tr>\n    <tr>\n      <th>20950</th>\n      <td>1012345706085011456</td>\n      <td>2018-06-28T14:43:19.000Z</td>\n    </tr>\n    <tr>\n      <th>20951</th>\n      <td>1012345764033519616</td>\n      <td>2018-06-28T14:43:33.000Z</td>\n    </tr>\n  </tbody>\n</table>\n<p>20952 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "politifact_fake_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n"
     ]
    }
   ],
   "source": [
    "tweet_times_g_fake = pd.DataFrame(columns=[\"id\", \"timestamps\"])\n",
    "for index, item in enumerate(politifact_fake_tweet_data):\n",
    "    for k in item:\n",
    "        for item_index, j in enumerate(item[k]):\n",
    "            if 'id' in j:\n",
    "                if tweet_times_p_fake['id'].str.contains(j['id']).any():\n",
    "                    try:\n",
    "                        current_index = tweet_times_p_fake.index[tweet_times_p_fake.id == j['id']].to_list()[0]\n",
    "                        tweet_times_p_fake.loc[current_index, 'timestamps'] += j['created_at']\n",
    "                    except IndexError as e:\n",
    "                        print(e)\n",
    "                else:\n",
    "                    tweet_times_p_fake = tweet_times_p_fake.append({'id':j['id'], 'timestamps':j['created_at']}, ignore_index=True)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                author_id tweets real_count fake_count\n",
       "32764  710856880680275969    NaN          0        311\n",
       "32928           144222146    NaN          0        266\n",
       "40659            18000449    NaN          0        185\n",
       "40553            23772575    NaN          0        133\n",
       "40578  790019230389248000    NaN          0         58\n",
       "...                   ...    ...        ...        ...\n",
       "15422            16377693    NaN          1          0\n",
       "15423            64465376    NaN          1          0\n",
       "15424            44999215    NaN          1          0\n",
       "15425            25969442    NaN          1          0\n",
       "22916            15469048    NaN          1          0\n",
       "\n",
       "[45833 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author_id</th>\n      <th>tweets</th>\n      <th>real_count</th>\n      <th>fake_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>32764</th>\n      <td>710856880680275969</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>311</td>\n    </tr>\n    <tr>\n      <th>32928</th>\n      <td>144222146</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>266</td>\n    </tr>\n    <tr>\n      <th>40659</th>\n      <td>18000449</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>185</td>\n    </tr>\n    <tr>\n      <th>40553</th>\n      <td>23772575</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>133</td>\n    </tr>\n    <tr>\n      <th>40578</th>\n      <td>790019230389248000</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15422</th>\n      <td>16377693</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15423</th>\n      <td>64465376</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15424</th>\n      <td>44999215</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15425</th>\n      <td>25969442</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22916</th>\n      <td>15469048</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>45833 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "tweets_by_author.sort_values(by=['fake_count'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                author_id tweets real_count fake_count\n",
       "44              612797013    NaN          8          1\n",
       "160              56135553    NaN          1          1\n",
       "199              49800332    NaN          2          1\n",
       "212             262797667    NaN          2          1\n",
       "215             566828522    NaN          1          1\n",
       "...                   ...    ...        ...        ...\n",
       "30396  946822648729915393    NaN          1          1\n",
       "30476           125767959    NaN          1          6\n",
       "30502           105272579    NaN          3          1\n",
       "30635            27229155    NaN          1          1\n",
       "30638            25432802    NaN          1          8\n",
       "\n",
       "[1258 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author_id</th>\n      <th>tweets</th>\n      <th>real_count</th>\n      <th>fake_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>44</th>\n      <td>612797013</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>160</th>\n      <td>56135553</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>49800332</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>212</th>\n      <td>262797667</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>215</th>\n      <td>566828522</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>30396</th>\n      <td>946822648729915393</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>30476</th>\n      <td>125767959</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>30502</th>\n      <td>105272579</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>30635</th>\n      <td>27229155</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>30638</th>\n      <td>25432802</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n<p>1258 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "test = tweets_by_author[tweets_by_author['fake_count']!=0]\n",
    "test = test[test['real_count']!=0]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_p_real = filtered_p_real[filtered_p_real['tweet_ids'].notnull()]\n",
    "\n",
    "def getTweetAuthors(tweet_ids_raw):\n",
    "    count = 0\n",
    "    print(tweet_ids_raw)\n",
    "    tweet_ids = re.split(r'\\\\t', tweet_ids_raw)\n",
    "    for tweet_id in tweet_ids:\n",
    "        if count < 1:\n",
    "            response = requests.get('https://api.twitter.com/2/tweets?ids={tweet_id}&tweet.fields=created_at&expansions=author_id&user.fields=created_at',  headers)\n",
    "            count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_by_author.to_csv(\"processed-data/tweets-by-author-politifact.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "432"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "len(politifact_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_p_fake = politifact_fake[politifact_fake['text'] != '' ]\n",
    "filtered_p_fake = filtered_p_fake[filtered_p_fake['text'].notnull()]\n",
    "filtered_p_fake = filtered_p_fake[filtered_p_fake['tweet_ids'].notnull()]\n",
    "# filtered_p_fake.to_csv('processed-data/scraped_text/politifact_fake_with_scraped_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  id                                           news_url  \\\n",
       "3    politifact14355  https://howafrica.com/oscar-pistorius-attempts...   \n",
       "7    politifact14795  https://web.archive.org/web/20171027105356/htt...   \n",
       "8    politifact14328  https://web.archive.org/web/20170702174006/htt...   \n",
       "19   politifact15178  https://www.politico.com/story/2017/05/09/trum...   \n",
       "22   politifact15267  https://www.independent.co.uk/arts-entertainme...   \n",
       "..               ...                                                ...   \n",
       "413  politifact14667  https://www.facebook.com/StopDjTrump/photos/a....   \n",
       "418  politifact15505  https://yournewswire.com/senate-report-clinton...   \n",
       "419  politifact14169  https://web.archive.org/web/20170528095037/htt...   \n",
       "422  politifact14158  https://web.archive.org/web/20170602190500/htt...   \n",
       "428  politifact14071  https://web.archive.org/web/20170322070001/htt...   \n",
       "\n",
       "                                                 title  \\\n",
       "3           Oscar Pistorius Attempts To Commit Suicide   \n",
       "7    Saudi Arabia to Behead 6 School Girls for Bein...   \n",
       "8    Malia Obama Fired From Cushy Internship At Spa...   \n",
       "19   Former presidents walk fine line in Trump’s Am...   \n",
       "22   Donald Trump inauguration: Artists who won't p...   \n",
       "..                                                 ...   \n",
       "413                                    Wake Up America   \n",
       "418  Senate Report Admits Clinton ‘Gifted’ Children...   \n",
       "419  Rubio: “Rape Victims Should Be In Custody If T...   \n",
       "422  WORSE THAN HITLER! Trey Gowdy’s Son Found In A...   \n",
       "428  Lindsey Graham Threatens To Convert To Democra...   \n",
       "\n",
       "                                             tweet_ids  \\\n",
       "3    886941526458347521\\t887011300278194176\\t887023...   \n",
       "7    923126512458616832\\t923135295070990341\\t923189...   \n",
       "8    880455776107679747\\t880457763876462598\\t880461...   \n",
       "19   861881844949688324\\t861881844697923585\\t861881...   \n",
       "22   812333495020195841\\t812333821945376773\\t812334...   \n",
       "..                                                 ...   \n",
       "413  1002128667819106304\\t1002129159420858368\\t1002...   \n",
       "418  1008393012563644416\\t1008396231964585984\\t1008...   \n",
       "419  663538460104392704\\t663757208031780864\\t663764...   \n",
       "422                                 865933040492703745   \n",
       "428  740351669834244096\\t740391312277573632\\t740474...   \n",
       "\n",
       "                                                  text  \n",
       "3                                    Home  Advertis...  \n",
       "7                   RELIGION MIND     Humanity's fi...  \n",
       "8                      Home  Politics   President T...  \n",
       "19          Skip to Main Content             POLITI...  \n",
       "22        Subscribe Login                  Subscrib...  \n",
       "..                                                 ...  \n",
       "413                                                     \n",
       "418                YourNewswire.com           Buy T...  \n",
       "419                            Facebook           U...  \n",
       "422          Daily USA Update      Menu   News  Pol...  \n",
       "428                 1                     Home  MyV...  \n",
       "\n",
       "[140 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>news_url</th>\n      <th>title</th>\n      <th>tweet_ids</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>politifact14355</td>\n      <td>https://howafrica.com/oscar-pistorius-attempts...</td>\n      <td>Oscar Pistorius Attempts To Commit Suicide</td>\n      <td>886941526458347521\\t887011300278194176\\t887023...</td>\n      <td>Home  Advertis...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>politifact14795</td>\n      <td>https://web.archive.org/web/20171027105356/htt...</td>\n      <td>Saudi Arabia to Behead 6 School Girls for Bein...</td>\n      <td>923126512458616832\\t923135295070990341\\t923189...</td>\n      <td>RELIGION MIND     Humanity's fi...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>politifact14328</td>\n      <td>https://web.archive.org/web/20170702174006/htt...</td>\n      <td>Malia Obama Fired From Cushy Internship At Spa...</td>\n      <td>880455776107679747\\t880457763876462598\\t880461...</td>\n      <td>Home  Politics   President T...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>politifact15178</td>\n      <td>https://www.politico.com/story/2017/05/09/trum...</td>\n      <td>Former presidents walk fine line in Trump’s Am...</td>\n      <td>861881844949688324\\t861881844697923585\\t861881...</td>\n      <td>Skip to Main Content             POLITI...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>politifact15267</td>\n      <td>https://www.independent.co.uk/arts-entertainme...</td>\n      <td>Donald Trump inauguration: Artists who won't p...</td>\n      <td>812333495020195841\\t812333821945376773\\t812334...</td>\n      <td>Subscribe Login                  Subscrib...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>413</th>\n      <td>politifact14667</td>\n      <td>https://www.facebook.com/StopDjTrump/photos/a....</td>\n      <td>Wake Up America</td>\n      <td>1002128667819106304\\t1002129159420858368\\t1002...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>418</th>\n      <td>politifact15505</td>\n      <td>https://yournewswire.com/senate-report-clinton...</td>\n      <td>Senate Report Admits Clinton ‘Gifted’ Children...</td>\n      <td>1008393012563644416\\t1008396231964585984\\t1008...</td>\n      <td>YourNewswire.com           Buy T...</td>\n    </tr>\n    <tr>\n      <th>419</th>\n      <td>politifact14169</td>\n      <td>https://web.archive.org/web/20170528095037/htt...</td>\n      <td>Rubio: “Rape Victims Should Be In Custody If T...</td>\n      <td>663538460104392704\\t663757208031780864\\t663764...</td>\n      <td>Facebook           U...</td>\n    </tr>\n    <tr>\n      <th>422</th>\n      <td>politifact14158</td>\n      <td>https://web.archive.org/web/20170602190500/htt...</td>\n      <td>WORSE THAN HITLER! Trey Gowdy’s Son Found In A...</td>\n      <td>865933040492703745</td>\n      <td>Daily USA Update      Menu   News  Pol...</td>\n    </tr>\n    <tr>\n      <th>428</th>\n      <td>politifact14071</td>\n      <td>https://web.archive.org/web/20170322070001/htt...</td>\n      <td>Lindsey Graham Threatens To Convert To Democra...</td>\n      <td>740351669834244096\\t740391312277573632\\t740474...</td>\n      <td>1                     Home  MyV...</td>\n    </tr>\n  </tbody>\n</table>\n<p>140 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "filtered_p_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'https://howafrica.com/oscar-pistorius-attempts-commit-suicide/'"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "filtered_p_fake.head(1).news_url.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_p_real.to_excel('processed-data/scraped_text_filtered/politifact_real.xlsx',engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Unnamed: 0               id  \\\n",
       "0             0  politifact14984   \n",
       "1             1  politifact12944   \n",
       "2             2    politifact333   \n",
       "3             3   politifact4358   \n",
       "4             4    politifact779   \n",
       "..          ...              ...   \n",
       "549         618  politifact13619   \n",
       "550         620    politifact329   \n",
       "551         621   politifact1576   \n",
       "552         622   politifact4720   \n",
       "553         623     politifact52   \n",
       "\n",
       "                                              news_url  \\\n",
       "0                            http://www.nfib-sbet.org/   \n",
       "1    http://www.cq.com/doc/newsmakertranscripts-494...   \n",
       "2    https://web.archive.org/web/20080204072132/htt...   \n",
       "3    https://web.archive.org/web/20110811143753/htt...   \n",
       "4    https://web.archive.org/web/20070820164107/htt...   \n",
       "..                                                 ...   \n",
       "549  http://www.cnn.com/2017/01/05/politics/border-...   \n",
       "550  https://web.archive.org/web/20080131000131/htt...   \n",
       "551         http://www.youtube.com/watch?v=4O8CxZ1OD58   \n",
       "552         http://www.youtube.com/watch?v=EhyMplwY6HY   \n",
       "553  https://web.archive.org/web/20071102131244/htt...   \n",
       "\n",
       "                                                 title  \\\n",
       "0          National Federation of Independent Business   \n",
       "1                          comments in Fayetteville NC   \n",
       "2    Romney makes pitch, hoping to close deal : Ele...   \n",
       "3    Democratic Leaders Say House Democrats Are Uni...   \n",
       "4      Budget of the United States Government, FY 2008   \n",
       "..                                                 ...   \n",
       "549  Trump asking Congress, not Mexico, to pay for ...   \n",
       "550                           Change We Can Believe In   \n",
       "551  deputy director of national health statistics ...   \n",
       "552  Romneys ProLife Conversion Myth or Reality Jun...   \n",
       "553                             Interest Group Ratings   \n",
       "\n",
       "                                             tweet_ids  \\\n",
       "0    967132259869487105\\t967164368768196609\\t967215...   \n",
       "1    942953459\\t8980098198\\t16253717352\\t1668513250...   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4    89804710374154240\\t91270460595109888\\t96039619...   \n",
       "..                                                 ...   \n",
       "549  817357495047979008\\t817357627566985217\\t817357...   \n",
       "550  634287923135909888\\t946743411100536832\\t946816...   \n",
       "551                                                NaN   \n",
       "552                                 188871706637647874   \n",
       "553           1002208963239337984\\t1024651239697666048   \n",
       "\n",
       "                                                  text  \n",
       "0                          At a Glance     Indicato...  \n",
       "1                                              Logi...  \n",
       "2              success  fail                       ...  \n",
       "3                  success  fail                   ...  \n",
       "4                  success  fail                   ...  \n",
       "..                                                 ...  \n",
       "549                       The Biden Presidency Fact...  \n",
       "550                   success  fail                ...  \n",
       "551  Over Pers Auteursrecht Contact Creators Advert...  \n",
       "552  Over Pers Auteursrecht Contact Creators Advert...  \n",
       "553                success  fail                   ...  \n",
       "\n",
       "[554 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>news_url</th>\n      <th>title</th>\n      <th>tweet_ids</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>politifact14984</td>\n      <td>http://www.nfib-sbet.org/</td>\n      <td>National Federation of Independent Business</td>\n      <td>967132259869487105\\t967164368768196609\\t967215...</td>\n      <td>At a Glance     Indicato...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>politifact12944</td>\n      <td>http://www.cq.com/doc/newsmakertranscripts-494...</td>\n      <td>comments in Fayetteville NC</td>\n      <td>942953459\\t8980098198\\t16253717352\\t1668513250...</td>\n      <td>Logi...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>politifact333</td>\n      <td>https://web.archive.org/web/20080204072132/htt...</td>\n      <td>Romney makes pitch, hoping to close deal : Ele...</td>\n      <td>NaN</td>\n      <td>success  fail                       ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>politifact4358</td>\n      <td>https://web.archive.org/web/20110811143753/htt...</td>\n      <td>Democratic Leaders Say House Democrats Are Uni...</td>\n      <td>NaN</td>\n      <td>success  fail                   ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>politifact779</td>\n      <td>https://web.archive.org/web/20070820164107/htt...</td>\n      <td>Budget of the United States Government, FY 2008</td>\n      <td>89804710374154240\\t91270460595109888\\t96039619...</td>\n      <td>success  fail                   ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>549</th>\n      <td>618</td>\n      <td>politifact13619</td>\n      <td>http://www.cnn.com/2017/01/05/politics/border-...</td>\n      <td>Trump asking Congress, not Mexico, to pay for ...</td>\n      <td>817357495047979008\\t817357627566985217\\t817357...</td>\n      <td>The Biden Presidency Fact...</td>\n    </tr>\n    <tr>\n      <th>550</th>\n      <td>620</td>\n      <td>politifact329</td>\n      <td>https://web.archive.org/web/20080131000131/htt...</td>\n      <td>Change We Can Believe In</td>\n      <td>634287923135909888\\t946743411100536832\\t946816...</td>\n      <td>success  fail                ...</td>\n    </tr>\n    <tr>\n      <th>551</th>\n      <td>621</td>\n      <td>politifact1576</td>\n      <td>http://www.youtube.com/watch?v=4O8CxZ1OD58</td>\n      <td>deputy director of national health statistics ...</td>\n      <td>NaN</td>\n      <td>Over Pers Auteursrecht Contact Creators Advert...</td>\n    </tr>\n    <tr>\n      <th>552</th>\n      <td>622</td>\n      <td>politifact4720</td>\n      <td>http://www.youtube.com/watch?v=EhyMplwY6HY</td>\n      <td>Romneys ProLife Conversion Myth or Reality Jun...</td>\n      <td>188871706637647874</td>\n      <td>Over Pers Auteursrecht Contact Creators Advert...</td>\n    </tr>\n    <tr>\n      <th>553</th>\n      <td>623</td>\n      <td>politifact52</td>\n      <td>https://web.archive.org/web/20071102131244/htt...</td>\n      <td>Interest Group Ratings</td>\n      <td>1002208963239337984\\t1024651239697666048</td>\n      <td>success  fail                   ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>554 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "filtered_p_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        author_id                created_at                   id  \\\n",
       "10267     8739282  2008-01-10T17:32:35.000Z            584359142   \n",
       "18941     5530062  2008-01-27T02:20:44.000Z            645557142   \n",
       "18942       13420  2008-01-27T02:23:38.000Z            645562962   \n",
       "18943    10235502  2008-01-27T03:40:24.000Z            645737242   \n",
       "18944     9252212  2008-01-27T04:03:45.000Z            645787662   \n",
       "...           ...                       ...                  ...   \n",
       "26687  2597987358  2018-12-13T19:41:37.000Z  1073301935569154053   \n",
       "26688  2533381116  2018-12-13T21:11:40.000Z  1073324601151651840   \n",
       "26689  2359065805  2018-12-14T00:21:23.000Z  1073372343072772097   \n",
       "23014    15018447  2018-12-14T20:46:54.000Z  1073680754910117889   \n",
       "23015    22012737  2018-12-15T16:16:59.000Z  1073975215086960640   \n",
       "\n",
       "                                                    text          news_id  \\\n",
       "10267  Received Obama \"Anti-Pledge of Allegiance\" ema...    politifact548   \n",
       "18941  \"This election is about the past versus the fu...    politifact323   \n",
       "18942  \"This election is about the past versus the fu...    politifact323   \n",
       "18943  \"This election is about the past versus the fu...    politifact323   \n",
       "18944  Obama: Campaign is about \"the future versus th...    politifact323   \n",
       "...                                                  ...              ...   \n",
       "26687  @FLOTUS 😂😂😂😂 Funny saying the person who wante...   politifact1202   \n",
       "26688  —MICHELLE OBAMA SIGNS BOOK—\\n\\nSecond stop, @T...   politifact1202   \n",
       "26689  @realDonaldTrump I'm still laughing today abou...   politifact1202   \n",
       "23014  Having to enroll or renew health insurance cov...  politifact13226   \n",
       "23015  @JerryLingle @realDonaldTrump Do people realiz...  politifact13226   \n",
       "\n",
       "      withheld  \n",
       "10267      NaN  \n",
       "18941      NaN  \n",
       "18942      NaN  \n",
       "18943      NaN  \n",
       "18944      NaN  \n",
       "...        ...  \n",
       "26687      NaN  \n",
       "26688      NaN  \n",
       "26689      NaN  \n",
       "23014      NaN  \n",
       "23015      NaN  \n",
       "\n",
       "[27210 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author_id</th>\n      <th>created_at</th>\n      <th>id</th>\n      <th>text</th>\n      <th>news_id</th>\n      <th>withheld</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10267</th>\n      <td>8739282</td>\n      <td>2008-01-10T17:32:35.000Z</td>\n      <td>584359142</td>\n      <td>Received Obama \"Anti-Pledge of Allegiance\" ema...</td>\n      <td>politifact548</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18941</th>\n      <td>5530062</td>\n      <td>2008-01-27T02:20:44.000Z</td>\n      <td>645557142</td>\n      <td>\"This election is about the past versus the fu...</td>\n      <td>politifact323</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18942</th>\n      <td>13420</td>\n      <td>2008-01-27T02:23:38.000Z</td>\n      <td>645562962</td>\n      <td>\"This election is about the past versus the fu...</td>\n      <td>politifact323</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18943</th>\n      <td>10235502</td>\n      <td>2008-01-27T03:40:24.000Z</td>\n      <td>645737242</td>\n      <td>\"This election is about the past versus the fu...</td>\n      <td>politifact323</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18944</th>\n      <td>9252212</td>\n      <td>2008-01-27T04:03:45.000Z</td>\n      <td>645787662</td>\n      <td>Obama: Campaign is about \"the future versus th...</td>\n      <td>politifact323</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>26687</th>\n      <td>2597987358</td>\n      <td>2018-12-13T19:41:37.000Z</td>\n      <td>1073301935569154053</td>\n      <td>@FLOTUS 😂😂😂😂 Funny saying the person who wante...</td>\n      <td>politifact1202</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>26688</th>\n      <td>2533381116</td>\n      <td>2018-12-13T21:11:40.000Z</td>\n      <td>1073324601151651840</td>\n      <td>—MICHELLE OBAMA SIGNS BOOK—\\n\\nSecond stop, @T...</td>\n      <td>politifact1202</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>26689</th>\n      <td>2359065805</td>\n      <td>2018-12-14T00:21:23.000Z</td>\n      <td>1073372343072772097</td>\n      <td>@realDonaldTrump I'm still laughing today abou...</td>\n      <td>politifact1202</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>23014</th>\n      <td>15018447</td>\n      <td>2018-12-14T20:46:54.000Z</td>\n      <td>1073680754910117889</td>\n      <td>Having to enroll or renew health insurance cov...</td>\n      <td>politifact13226</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>23015</th>\n      <td>22012737</td>\n      <td>2018-12-15T16:16:59.000Z</td>\n      <td>1073975215086960640</td>\n      <td>@JerryLingle @realDonaldTrump Do people realiz...</td>\n      <td>politifact13226</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>27210 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "source": [
    "politifact_real_df.sort_values('created_at')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "19664"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "len(politifact_real_df['author_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "politifact_real_manually_checked = pd.read_excel('processed-data/scraped_text_filtered/politifact_real_manually_checked.xlsx', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/vangelistrikoupis/miniforge3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3169: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "p_tweet_times_real = pd.read_csv('processed-data/tweet_times/politifact_real_tweet_times.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}