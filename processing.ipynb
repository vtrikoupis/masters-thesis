{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd0730a29a129caaf396252390d0f158bf1f8c297b87c9b8a65cd66b7ca36b66f6f",
   "display_name": "Python 3.9.2 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "730a29a129caaf396252390d0f158bf1f8c297b87c9b8a65cd66b7ca36b66f6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Data Wrangling - Fetching step\n",
    "- The gossipcop and politifact fake and real news datasets are loaded in pandas dataframes.\n",
    "- Using urllib and bs4, the original news article is downloaded if available and relevant text is kept from the html\n",
    "- Using urllib, the twitter API is used to collect the `author_id` of fake and real news\n",
    "- Using urllib, the twitter API is used to collect the `created_at` timestamp of real and fake news\n",
    "\n",
    "Requirements:\n",
    "\n",
    "`.env` file at the root of the repo containing BEARER_TOKEN = XXX where XXX should be replaced with a Twitter API V2 token"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None \n",
    "from tqdm.notebook import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.parse import urlparse\n",
    "from urllib.error import HTTPError, URLError\n",
    "from json.decoder import JSONDecodeError\n",
    "from http.client import RemoteDisconnected\n",
    "import requests\n",
    "from requests import exceptions\n",
    "import logging\n",
    "from socket import timeout\n",
    "import re\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from regex import remove_single_char, remove_numbers, remove_urls, remove_emojis, remove_nonalpha, remove_extra_spaces, remove_rt\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 55,
   "outputs": []
  },
  {
   "source": [
    "### 1. Set up the request headers by loading the bearer token from the `.env` file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token = os.environ.get(\"BEARER_TOKEN\")\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {bearer_token}'\n",
    "}"
   ]
  },
  {
   "source": [
    "### 2. Helper functions for processing html files using beautifulsoup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    return u\" \".join(t.strip() for t in visible_texts)\n",
    "\n",
    "def process_url(url):\n",
    "    req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    try:\n",
    "        html = urlopen(req, timeout = 10)\n",
    "        html = html.read()\n",
    "        return text_from_html(html)\n",
    "    except timeout:\n",
    "        print(\"connection timedout\")\n",
    "    except RemoteDisconnected as e:\n",
    "        print(e)\n",
    "    except ProtocolError as e:\n",
    "        print(e)\n",
    "    except URLError as e:\n",
    "        print(e)\n",
    "    except ConnectionError:\n",
    "        print(\"conn reset\")\n",
    "        print(url)\n",
    "    except HTTPError as err:\n",
    "        if err.code == 410 or 404:\n",
    "            print(\"permanently deleted or removed, url should be removed\")\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "source": [
    "### Steps 3-7 below are commented out and the previously generated output is loaded into the variables\n",
    " - `filtered_p_fake`: filtered politifact fake news with the scraped text from the original article \n",
    " - `filtered_p_real`: filtered politifact real news with the scraped text from the original article \n",
    " - `filtered_g_fake`: filtered gossipcop fake news with the scraped text from the original article \n",
    " - `filtered_g_real`: filtered gossipcop real news with the scraped text from the original article "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "politifact_fake = pd.read_csv('fakenewsnet/politifact_fake.csv')\n",
    "filtered_p_fake = pd.read_csv('processed-data/scraped_text/politifact_fake_with_scraped_text.csv')\n",
    "\n",
    "politifact_real = pd.read_csv('fakenewsnet/politifact_real.csv')\n",
    "filtered_p_real = pd.read_csv('processed-data/scraped_text/politifact_real_with_scraped_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gossipcop_fake = pd.read_csv('fakenewsnet/gossipcop_fake.csv')\n",
    "filtered_g_fake = pd.read_csv('processed-data/scraped_text/gossipcop_fake_with_scraped_text.csv')\n",
    "\n",
    "gossipcop_real = pd.read_csv('fakenewsnet/gossipcop_real.csv')\n",
    "filtered_g_real = pd.read_csv('processed-data/scraped_text/gossipcop_real_with_scraped_text.csv')"
   ]
  },
  {
   "source": [
    "### 3. Fetching the original article for the real news in the politifact dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'text' not in politifact_real:\n",
    "#     politifact_real['text'] = ''\n",
    "# for index, url in enumerate(tqdm(politifact_real['news_url'])):\n",
    "#     if politifact_real['text'].iloc[index] == '':\n",
    "#         if type(url) != float:\n",
    "#             if urlparse(url).scheme:\n",
    "#                 if politifact_real['text'].iloc[index] == '':\n",
    "#                     politifact_real['text'].iloc[index] = process_url(url)"
   ]
  },
  {
   "source": [
    "### 4. Fetching the original article for the fake news in the politifact dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if 'text' not in politifact_fake:\n",
    "#     politifact_fake['text'] = ''\n",
    "# for index, url in enumerate(tqdm(politifact_fake['news_url'])):\n",
    "#     if politifact_fake['text'].iloc[index] == '':\n",
    "#         if type(url) != float:\n",
    "#             if urlparse(url).scheme:\n",
    "#                 if politifact_fake['text'].iloc[index] == '':\n",
    "#                     politifact_fake['text'].iloc[index] = process_url(url)"
   ]
  },
  {
   "source": [
    "### 5. Fetching the original article for the real news in the gossipcop dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if 'text' not in gossipcop_real:\n",
    "#     gossipcop_real['text'] = ''\n",
    "# for index, url in enumerate(tqdm(gossipcop_real['news_url'])):\n",
    "#     if gossipcop_real['text'].iloc[index] == '':\n",
    "#         if type(url) != float:\n",
    "#            if urlparse(url).scheme:\n",
    "#                 if gossipcop_real['text'].iloc[index] == '':\n",
    "#                     gossipcop_real['text'].iloc[index] = process_url(url)\n",
    "#                 elif \"://\" in url: \n",
    "#                     if gossipcop_real['text'].iloc[index] == '':\n",
    "#                         gossipcop_real['text'].iloc[index] = process_url(url)\n",
    "#                 else: \n",
    "#                     url = \"http://\" + url\n",
    "#                     if gossipcop_real['text'].iloc[index] == '':\n",
    "#                         gossipcop_real['text'].iloc[index] = process_url(url)"
   ]
  },
  {
   "source": [
    "### 6. Fetching the original article for the fake news in the gossipcop dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if 'text' not in gossipcop_fake:\n",
    "#     gossipcop_fake['text'] = ''\n",
    "# for index, url in enumerate(tqdm(gossipcop_fake['news_url'])):\n",
    "#     if gossipcop_fake['text'].iloc[index] == '':\n",
    "#         if type(url) != float:\n",
    "#             if \"://\" in url: \n",
    "#                 gossipcop_fake['text'].iloc[index] = process_url(url)\n",
    "#             else:\n",
    "#                 url = \"http://\" + url\n",
    "#                 gossipcop_fake['text'].iloc[index] = process_url(url)"
   ]
  },
  {
   "source": [
    "### 7. In some cases, especially for fake news, the article has been removed from the internet and the text is therefore not available. Filter out these instances and drop the rows as topic modelling will not be applicable here"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_g_fake = gossipcop_fake[gossipcop_fake['text'] != '' ]\n",
    "# filtered_g_fake = filtered_g_fake[filtered_g_fake['text'].notnull()]\n",
    "# filtered_g_fake = filtered_g_fake[filtered_g_fake['tweet_ids'].notnull()]\n",
    "# filtered_g_fake.to_csv('processed-data/scraped_text/gossipcop_fake_with_scraped_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_g_real = gossipcop_real[gossipcop_real['text'] != '' ]\n",
    "# filtered_g_real = filtered_g_real[filtered_g_real['text'].notnull()]\n",
    "# filtered_g_real = filtered_g_real[filtered_g_real['tweet_ids'].notnull()]\n",
    "# filtered_g_real.to_csv('processed-data/scraped_text/gossipcop_real_with_scraped_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_p_fake = politifact_fake[politifact_fake['text'] != '' ]\n",
    "filtered_p_fake = filtered_p_fake[filtered_p_fake['text'].notnull()]\n",
    "filtered_p_fake = filtered_p_fake[filtered_p_fake['tweet_ids'].notnull()]\n",
    "# filtered_p_fake.to_csv('processed-data/scraped_text/politifact_fake_with_scraped_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_p_real = politifact_real[politifact_real['text'] != '' ]\n",
    "filtered_p_real = filtered_p_real[filtered_p_real['text'].notnull()]\n",
    "filtered_p_real = filtered_p_real[filtered_p_real['tweet_ids'].notnull()]\n",
    "# filtered_p_real.to_csv('processed-data/scraped_text/politifact_real_with_scraped_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Unnamed: 0               id  \\\n",
       "0             0  politifact14984   \n",
       "1             1  politifact12944   \n",
       "4             4    politifact779   \n",
       "5             5  politifact14064   \n",
       "6             6  politifact14474   \n",
       "..          ...              ...   \n",
       "548         617   politifact6931   \n",
       "549         618  politifact13619   \n",
       "550         620    politifact329   \n",
       "552         622   politifact4720   \n",
       "553         623     politifact52   \n",
       "\n",
       "                                              news_url  \\\n",
       "0                            http://www.nfib-sbet.org/   \n",
       "1    http://www.cq.com/doc/newsmakertranscripts-494...   \n",
       "4    https://web.archive.org/web/20070820164107/htt...   \n",
       "5    http://www.politifact.com/truth-o-meter/statem...   \n",
       "6    https://www.law.cornell.edu/constitution/amend...   \n",
       "..                                                 ...   \n",
       "548  http://www.politifact.com/truth-o-meter/promis...   \n",
       "549  http://www.cnn.com/2017/01/05/politics/border-...   \n",
       "550  https://web.archive.org/web/20080131000131/htt...   \n",
       "552         http://www.youtube.com/watch?v=EhyMplwY6HY   \n",
       "553  https://web.archive.org/web/20071102131244/htt...   \n",
       "\n",
       "                                                 title  \\\n",
       "0          National Federation of Independent Business   \n",
       "1                          comments in Fayetteville NC   \n",
       "4      Budget of the United States Government, FY 2008   \n",
       "5    Donald Trump exaggerates when he says China ha...   \n",
       "6                                       25th Amendment   \n",
       "..                                                 ...   \n",
       "548  The Obameter: Introduce a comprehensive immigr...   \n",
       "549  Trump asking Congress, not Mexico, to pay for ...   \n",
       "550                           Change We Can Believe In   \n",
       "552  Romneys ProLife Conversion Myth or Reality Jun...   \n",
       "553                             Interest Group Ratings   \n",
       "\n",
       "                                             tweet_ids  \\\n",
       "0    967132259869487105\\t967164368768196609\\t967215...   \n",
       "1    942953459\\t8980098198\\t16253717352\\t1668513250...   \n",
       "4    89804710374154240\\t91270460595109888\\t96039619...   \n",
       "5    690248006399049728\\t690254026663821312\\t690276...   \n",
       "6    1262604762\\t10969740933\\t11182364398\\t17507543...   \n",
       "..                                                 ...   \n",
       "548  21096374968\\t21096771824\\t9413452992876544\\t12...   \n",
       "549  817357495047979008\\t817357627566985217\\t817357...   \n",
       "550  634287923135909888\\t946743411100536832\\t946816...   \n",
       "552                                 188871706637647874   \n",
       "553           1002208963239337984\\t1024651239697666048   \n",
       "\n",
       "                                                  text  \n",
       "0                          At a Glance     Indicato...  \n",
       "1                                              Logi...  \n",
       "4                  success  fail                   ...  \n",
       "5                                   The Poynter Ins...  \n",
       "6                                      Please help ...  \n",
       "..                                                 ...  \n",
       "548                                 The Poynter Ins...  \n",
       "549                       The Biden Presidency Fact...  \n",
       "550                   success  fail                ...  \n",
       "552  Over Pers Auteursrecht Contact Creators Advert...  \n",
       "553                success  fail                   ...  \n",
       "\n",
       "[329 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>news_url</th>\n      <th>title</th>\n      <th>tweet_ids</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>politifact14984</td>\n      <td>http://www.nfib-sbet.org/</td>\n      <td>National Federation of Independent Business</td>\n      <td>967132259869487105\\t967164368768196609\\t967215...</td>\n      <td>At a Glance     Indicato...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>politifact12944</td>\n      <td>http://www.cq.com/doc/newsmakertranscripts-494...</td>\n      <td>comments in Fayetteville NC</td>\n      <td>942953459\\t8980098198\\t16253717352\\t1668513250...</td>\n      <td>Logi...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>politifact779</td>\n      <td>https://web.archive.org/web/20070820164107/htt...</td>\n      <td>Budget of the United States Government, FY 2008</td>\n      <td>89804710374154240\\t91270460595109888\\t96039619...</td>\n      <td>success  fail                   ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>politifact14064</td>\n      <td>http://www.politifact.com/truth-o-meter/statem...</td>\n      <td>Donald Trump exaggerates when he says China ha...</td>\n      <td>690248006399049728\\t690254026663821312\\t690276...</td>\n      <td>The Poynter Ins...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>politifact14474</td>\n      <td>https://www.law.cornell.edu/constitution/amend...</td>\n      <td>25th Amendment</td>\n      <td>1262604762\\t10969740933\\t11182364398\\t17507543...</td>\n      <td>Please help ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>548</th>\n      <td>617</td>\n      <td>politifact6931</td>\n      <td>http://www.politifact.com/truth-o-meter/promis...</td>\n      <td>The Obameter: Introduce a comprehensive immigr...</td>\n      <td>21096374968\\t21096771824\\t9413452992876544\\t12...</td>\n      <td>The Poynter Ins...</td>\n    </tr>\n    <tr>\n      <th>549</th>\n      <td>618</td>\n      <td>politifact13619</td>\n      <td>http://www.cnn.com/2017/01/05/politics/border-...</td>\n      <td>Trump asking Congress, not Mexico, to pay for ...</td>\n      <td>817357495047979008\\t817357627566985217\\t817357...</td>\n      <td>The Biden Presidency Fact...</td>\n    </tr>\n    <tr>\n      <th>550</th>\n      <td>620</td>\n      <td>politifact329</td>\n      <td>https://web.archive.org/web/20080131000131/htt...</td>\n      <td>Change We Can Believe In</td>\n      <td>634287923135909888\\t946743411100536832\\t946816...</td>\n      <td>success  fail                ...</td>\n    </tr>\n    <tr>\n      <th>552</th>\n      <td>622</td>\n      <td>politifact4720</td>\n      <td>http://www.youtube.com/watch?v=EhyMplwY6HY</td>\n      <td>Romneys ProLife Conversion Myth or Reality Jun...</td>\n      <td>188871706637647874</td>\n      <td>Over Pers Auteursrecht Contact Creators Advert...</td>\n    </tr>\n    <tr>\n      <th>553</th>\n      <td>623</td>\n      <td>politifact52</td>\n      <td>https://web.archive.org/web/20071102131244/htt...</td>\n      <td>Interest Group Ratings</td>\n      <td>1002208963239337984\\t1024651239697666048</td>\n      <td>success  fail                   ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>329 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "filtered_p_real"
   ]
  },
  {
   "source": [
    "### 8. Tweet processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "BaseSSLError = ssl.SSLError"
   ]
  },
  {
   "source": [
    "politifact_real_tweet_data = []\n",
    "response_count = 0\n",
    "\n",
    "try:\n",
    "    politifact_real_tweet_dataframe\n",
    "except NameError:\n",
    "    print('Creating new dataframe for real tweets')\n",
    "else:\n",
    "    politifact_real_tweet_dataframe = pd.DataFrame(columns=['news_id'])\n",
    "for index, tweet_ids in enumerate(tqdm(filtered_p_real['tweet_ids'])):\n",
    "    if type(tweet_ids) != float:\n",
    "        tweet_id_list = tweet_ids.split()\n",
    "        # print(tweet_id_list)\n",
    "        temp_data_for_author = []\n",
    "        # print(index % 100)\n",
    "        temp_list_of_100 = ''\n",
    "        # print(len(tweet_id_list))\n",
    "        for tweet_index, tweet_id in enumerate(tweet_id_list):\n",
    "            if tweet_index % 100 == 0 and tweet_index > 0:\n",
    "                if temp_list_of_100.endswith(','):\n",
    "                    temp_list_of_100 = temp_list_of_100[:-1]\n",
    "                try:\n",
    "                        response = requests.get(f'https://api.twitter.com/2/tweets?ids={temp_list_of_100}&tweet.fields=created_at,author_id',  headers=headers)\n",
    "                except (ConnectionError, exceptions.RequestException) as e:\n",
    "                    print(e)\n",
    "                    time.sleep(900)\n",
    "                    index-=1;\n",
    "                temp_list_of_100 = ''\n",
    "                # else:\n",
    "                #     time.sleep(3)\n",
    "                #     response = requests.get(f'https://api.twitter.com/2/tweets?ids={temp_list_of_100}&tweet.fields=created_at,author_id',  headers=headers) \n",
    "                #     temp_list_of_100 = ''\n",
    "                try:\n",
    "                    data = response.json()\n",
    "                except JSONDecodeError as e:\n",
    "                    continue\n",
    "                if 'data' in data:\n",
    "                    for item in data['data']:\n",
    "                        if 'created_at' in item:\n",
    "                            item['news_id'] = filtered_p_real.iloc[index]['id']\n",
    "                            if filtered_p_real.iloc[index]['id'] not in politifact_real_tweet_dataframe['news_id'].to_list():\n",
    "                                politifact_real_tweet_data.append(item)\n",
    "            elif tweet_index % 100 == 99:\n",
    "                temp_list_of_100 = temp_list_of_100 + f'{tweet_id},'\n",
    "            # same if it's the last of the batch we process\n",
    "            elif tweet_index == len(filtered_p_real['tweet_ids'])-1:\n",
    "                temp_list_of_100 = temp_list_of_100 + f'{tweet_id},'\n",
    "            # otherwise we got to separate with a comma\n",
    "            else:\n",
    "                temp_list_of_100 = temp_list_of_100 + f'{tweet_id},'"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 56,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/329 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "86534d5169ac4addb83094c2bdd33110"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))\n",
      "('Connection aborted.', OSError(22, 'Invalid argument'))\n",
      "('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))\n",
      "('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))\n",
      "('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/205 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "09953853999f4653b0c639feefeb4083"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('Connection aborted.', OSError(22, 'Invalid argument'))\n"
     ]
    }
   ],
   "source": [
    "politifact_fake_tweet_data = []\n",
    "politifact_fake_tweet_dataframe = pd.DataFrame(columns=['news_id'])\n",
    "\n",
    "try:\n",
    "    politifact_fake_tweet_dataframe\n",
    "except NameError:\n",
    "    print('Creating new dataframe for fake tweets')\n",
    "else:\n",
    "    politifact_fake_tweet_dataframe = pd.DataFrame(columns=['news_id'])\n",
    "for index, tweet_ids in enumerate(tqdm(filtered_p_fake['tweet_ids'])):\n",
    "    if type(tweet_ids) != float:\n",
    "        tweet_id_list = tweet_ids.split()\n",
    "        # print(tweet_id_list)\n",
    "        temp_data_for_author = []\n",
    "        # print(index % 100)\n",
    "        temp_list_of_100 = ''\n",
    "        # print(len(tweet_id_list))\n",
    "        for tweet_index, tweet_id in enumerate(tweet_id_list):\n",
    "            if tweet_index % 100 == 0 and tweet_index > 0:\n",
    "                if temp_list_of_100.endswith(','):\n",
    "                    temp_list_of_100 = temp_list_of_100[:-1]\n",
    "                try:\n",
    "                        response = requests.get(f'https://api.twitter.com/2/tweets?ids={temp_list_of_100}&tweet.fields=created_at,author_id',  headers=headers)\n",
    "                except (ConnectionError, exceptions.RequestException) as e:\n",
    "                    print(e)\n",
    "                    time.sleep(900)\n",
    "                    index-=1;\n",
    "                temp_list_of_100 = ''\n",
    "                try:\n",
    "                    data = response.json()\n",
    "                except JSONDecodeError as e:\n",
    "                    continue\n",
    "                if 'data' in data:\n",
    "                    for item in data['data']:\n",
    "                        if 'created_at' in item:\n",
    "                            item['news_id'] = filtered_p_fake.iloc[index]['id']\n",
    "                            if filtered_p_fake.iloc[index]['id'] not in politifact_fake_tweet_dataframe['news_id'].to_list():\n",
    "                                politifact_fake_tweet_data.append(item)\n",
    "               \n",
    "            elif tweet_index % 100 == 99:\n",
    "                temp_list_of_100 = temp_list_of_100 + f'{tweet_id},'\n",
    "            # same if it's the last of the batch we process\n",
    "            elif tweet_index == len(filtered_p_fake['tweet_ids'])-1:\n",
    "                temp_list_of_100 = temp_list_of_100 + f'{tweet_id},'\n",
    "            # otherwise we got to separate with a comma\n",
    "            else:\n",
    "                temp_list_of_100 = temp_list_of_100 + f'{tweet_id},'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politifact_real_tweet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "politifact_fake_df = pd.DataFrame(politifact_fake_tweet_data)\n",
    "politifact_fake_df = politifact_fake_df.drop_duplicates(subset=['news_id','author_id'])\n",
    "politifact_fake_author_counts = politifact_fake_df['author_id'].value_counts()\n",
    "politifact_fake_counts = pd.DataFrame()\n",
    "politifact_fake_counts['fake'] = politifact_real_author_counts\n",
    "politifact_fake_counts['author_id'] = politifact_counts.index\n",
    "politifact_real_df = pd.DataFrame(politifact_real_tweet_data)\n",
    "politifact_real_df = politifact_real_df.drop_duplicates(subset=['news_id','author_id'])\n",
    "politifact_real_author_counts = politifact_real_df['author_id'].value_counts()\n",
    "politifact_counts['real'] = politifact_real_author_counts\n",
    "politifact_counts_merged = politifact_counts.merge(politifact_fake_counts, on=\"author_id\", how = 'inner')\n",
    "# politifact_counts_merged = politifact_counts_merged.reset_index()\n",
    "# politifact_counts_merged.to_csv('processed-data/tweet_counts_by_author_politifact.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    real           author_id\n",
       "48470839              36            48470839\n",
       "34383891              29            34383891\n",
       "1179710990            27          1179710990\n",
       "369760961             24           369760961\n",
       "15523710              21            15523710\n",
       "...                  ...                 ...\n",
       "2816232049             1          2816232049\n",
       "2376305339             1          2376305339\n",
       "794150830446440448     1  794150830446440448\n",
       "84431570               1            84431570\n",
       "19378586               1            19378586\n",
       "\n",
       "[148189 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>real</th>\n      <th>author_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>48470839</th>\n      <td>36</td>\n      <td>48470839</td>\n    </tr>\n    <tr>\n      <th>34383891</th>\n      <td>29</td>\n      <td>34383891</td>\n    </tr>\n    <tr>\n      <th>1179710990</th>\n      <td>27</td>\n      <td>1179710990</td>\n    </tr>\n    <tr>\n      <th>369760961</th>\n      <td>24</td>\n      <td>369760961</td>\n    </tr>\n    <tr>\n      <th>15523710</th>\n      <td>21</td>\n      <td>15523710</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2816232049</th>\n      <td>1</td>\n      <td>2816232049</td>\n    </tr>\n    <tr>\n      <th>2376305339</th>\n      <td>1</td>\n      <td>2376305339</td>\n    </tr>\n    <tr>\n      <th>794150830446440448</th>\n      <td>1</td>\n      <td>794150830446440448</td>\n    </tr>\n    <tr>\n      <th>84431570</th>\n      <td>1</td>\n      <td>84431570</td>\n    </tr>\n    <tr>\n      <th>19378586</th>\n      <td>1</td>\n      <td>19378586</td>\n    </tr>\n  </tbody>\n</table>\n<p>148189 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-208-c94254f2eced>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolitifact_real_tweet_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'author_id'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtweets_by_author\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'author_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'author_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0mcurrent_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweets_by_author\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweets_by_author\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthor_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'author_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/pandas/core/strings/accessor.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m                 )\n\u001b[1;32m    100\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/pandas/core/strings/accessor.py\u001b[0m in \u001b[0;36mcontains\u001b[0;34m(self, pat, case, flags, na, regex)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \"\"\"\n\u001b[0;32m-> 1110\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str_contains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns_string\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/pandas/core/strings/object_array.py\u001b[0m in \u001b[0;36m_str_contains\u001b[0;34m(self, pat, case, flags, na, regex)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0mupper_pat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mupper_pat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bool\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_str_startswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/pandas/core/strings/object_array.py\u001b[0m in \u001b[0;36m_str_map\u001b[0;34m(self, f, na_value, dtype)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mconvert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;31m# Reraise the exception if callable `f` got wrong number of args.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tweets_by_author = pd.DataFrame(columns=[\"author_id\", \"tweets\", \"real_count\", \"fake_count\"])\n",
    "\n",
    "for index, item in enumerate(politifact_real_tweet_data):\n",
    "    if 'author_id' in item:\n",
    "        if tweets_by_author['author_id'].str.contains(item['author_id']).any():\n",
    "            try:\n",
    "                current_index = tweets_by_author.index[tweets_by_author.author_id == item['author_id']].tolist()[0]\n",
    "                tweets_by_author.loc[current_index, 'real_count'] += 1\n",
    "            except IndexError as e:\n",
    "                print(e)\n",
    "        else: \n",
    "            tweets_by_author = tweets_by_author.append({'author_id':item['author_id'],'real_count':1, 'fake_count':0}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweet_times_p_real = pd.DataFrame(columns=[\"id\", \"timestamps\"])\n",
    "for index, item in enumerate(politifact_real_tweet_data):\n",
    "    for k in item:\n",
    "        for item_index, j in enumerate(item[k]):\n",
    "            if 'id' in j:\n",
    "                if tweet_times_p_real['id'].str.contains(j['id']).any():\n",
    "                    try:\n",
    "                        current_index = tweet_times_p_real.index[tweet_times_p_real.id == j['id']].to_list()[0]\n",
    "                        created_at = j['created_at']\n",
    "                        tweet_times_p_real.loc[current_index, 'timestamps'] += f',{created_at}' \n",
    "                    except IndexError as e:\n",
    "                        print(e)\n",
    "                else:\n",
    "                    tweet_times_p_real = tweet_times_p_real.append({'id':j['id'], 'timestamps':j['created_at']}, ignore_index=True)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_times_p_fake = pd.DataFrame(columns=[\"id\", \"timestamps\"])\n",
    "for index, item in enumerate(politifact_fake_tweet_data):\n",
    "    for k in item:\n",
    "        for item_index, j in enumerate(item[k]):\n",
    "            if 'id' in j:\n",
    "                if tweet_times_p_fake['id'].str.contains(j['id']).any():\n",
    "                    try:\n",
    "                        current_index = tweet_times_p_fake.index[tweet_times_p_fake.id == j['id']].to_list()[0]\n",
    "                        tweet_times_p_fake.loc[current_index, 'timestamps'] += j['created_at']\n",
    "                    except IndexError as e:\n",
    "                        print(e)\n",
    "                else:\n",
    "                    tweet_times_p_fake = tweet_times_p_fake.append({'id':j['id'], 'timestamps':j['created_at']}, ignore_index=True)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, timestamps]\n",
       "Index: []"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>timestamps</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "tweet_times_p_fake[tweet_times_p_fake['timestamps'].str.len()>24]\n",
    "# tweet_times_p_fake[tweet_times_p_fake['id']=='']['timestamps'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_times_g_fake = pd.DataFrame(columns=[\"id\", \"timestamps\"])\n",
    "for index, item in enumerate(politifact_fake_tweet_data):\n",
    "    for k in item:\n",
    "        for item_index, j in enumerate(item[k]):\n",
    "            if 'id' in j:\n",
    "                if tweet_times_p_fake['id'].str.contains(j['id']).any():\n",
    "                    try:\n",
    "                        current_index = tweet_times_p_fake.index[tweet_times_p_fake.id == j['id']].to_list()[0]\n",
    "                        tweet_times_p_fake.loc[current_index, 'timestamps'] += j['created_at']\n",
    "                    except IndexError as e:\n",
    "                        print(e)\n",
    "                else:\n",
    "                    tweet_times_p_fake = tweet_times_p_fake.append({'id':j['id'], 'timestamps':j['created_at']}, ignore_index=True)\n",
    "           "
   ]
  },
  {
   "source": [
    "### Politifact fake processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Unnamed: 0               id  \\\n",
       "0             3  politifact14355   \n",
       "1             4  politifact15371   \n",
       "3             7  politifact14795   \n",
       "4             8  politifact14328   \n",
       "5             9  politifact13775   \n",
       "..          ...              ...   \n",
       "228         419  politifact14169   \n",
       "229         421  politifact14992   \n",
       "230         422  politifact14158   \n",
       "231         427  politifact14944   \n",
       "232         428  politifact14071   \n",
       "\n",
       "                                              news_url  \\\n",
       "0    https://howafrica.com/oscar-pistorius-attempts...   \n",
       "1    http://washingtonsources.org/trump-votes-for-d...   \n",
       "3    https://web.archive.org/web/20171027105356/htt...   \n",
       "4    https://web.archive.org/web/20170702174006/htt...   \n",
       "5    http://beforeitsnews.com/opinion-conservative/...   \n",
       "..                                                 ...   \n",
       "228  https://web.archive.org/web/20170528095037/htt...   \n",
       "229  http://www.trainnews.info/2018/01/rep-paul-gos...   \n",
       "230  https://web.archive.org/web/20170602190500/htt...   \n",
       "231  http://thehill.com/homenews/senate/369928-who-...   \n",
       "232  https://web.archive.org/web/20170322070001/htt...   \n",
       "\n",
       "                                                 title  \\\n",
       "0           Oscar Pistorius Attempts To Commit Suicide   \n",
       "1          Trump Votes For Death Penalty For Being Gay   \n",
       "3    Saudi Arabia to Behead 6 School Girls for Bein...   \n",
       "4    Malia Obama Fired From Cushy Internship At Spa...   \n",
       "5             Target to Discontinue Sale of Holy Bible   \n",
       "..                                                 ...   \n",
       "228  Rubio: “Rape Victims Should Be In Custody If T...   \n",
       "229  Rep. Paul Gosar Asks Capitol Police to Arrest ...   \n",
       "230  WORSE THAN HITLER! Trey Gowdy’s Son Found In A...   \n",
       "231        Who is affected by the government shutdown?   \n",
       "232  Lindsey Graham Threatens To Convert To Democra...   \n",
       "\n",
       "                                             tweet_ids  \\\n",
       "0    886941526458347521\\t887011300278194176\\t887023...   \n",
       "1    915205698212040704\\t915242076681506816\\t915249...   \n",
       "3    923126512458616832\\t923135295070990341\\t923189...   \n",
       "4    880455776107679747\\t880457763876462598\\t880461...   \n",
       "5    732741826084397057\\t732741823534227456\\t732741...   \n",
       "..                                                 ...   \n",
       "228  663538460104392704\\t663757208031780864\\t663764...   \n",
       "229  958425300144218112\\t958428242528145409\\t958428...   \n",
       "230                                 865933040492703745   \n",
       "231  954602090462146560\\t954602093171609600\\t954650...   \n",
       "232  740351669834244096\\t740391312277573632\\t740474...   \n",
       "\n",
       "                                                  text  \n",
       "0                                    Home  Advertis...  \n",
       "1                       Washington Sources         ...  \n",
       "3                  success  fail                   ...  \n",
       "4                     success  fail                ...  \n",
       "5                             You're using an Ad-Bl...  \n",
       "..                                                 ...  \n",
       "228             success  fail                      ...  \n",
       "229      Home Business Online Business Bitcoin Revi...  \n",
       "230                success  fail                   ...  \n",
       "231                                                ...  \n",
       "232                           success  fail        ...  \n",
       "\n",
       "[205 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>news_url</th>\n      <th>title</th>\n      <th>tweet_ids</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>politifact14355</td>\n      <td>https://howafrica.com/oscar-pistorius-attempts...</td>\n      <td>Oscar Pistorius Attempts To Commit Suicide</td>\n      <td>886941526458347521\\t887011300278194176\\t887023...</td>\n      <td>Home  Advertis...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>politifact15371</td>\n      <td>http://washingtonsources.org/trump-votes-for-d...</td>\n      <td>Trump Votes For Death Penalty For Being Gay</td>\n      <td>915205698212040704\\t915242076681506816\\t915249...</td>\n      <td>Washington Sources         ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>politifact14795</td>\n      <td>https://web.archive.org/web/20171027105356/htt...</td>\n      <td>Saudi Arabia to Behead 6 School Girls for Bein...</td>\n      <td>923126512458616832\\t923135295070990341\\t923189...</td>\n      <td>success  fail                   ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8</td>\n      <td>politifact14328</td>\n      <td>https://web.archive.org/web/20170702174006/htt...</td>\n      <td>Malia Obama Fired From Cushy Internship At Spa...</td>\n      <td>880455776107679747\\t880457763876462598\\t880461...</td>\n      <td>success  fail                ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>9</td>\n      <td>politifact13775</td>\n      <td>http://beforeitsnews.com/opinion-conservative/...</td>\n      <td>Target to Discontinue Sale of Holy Bible</td>\n      <td>732741826084397057\\t732741823534227456\\t732741...</td>\n      <td>You're using an Ad-Bl...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>228</th>\n      <td>419</td>\n      <td>politifact14169</td>\n      <td>https://web.archive.org/web/20170528095037/htt...</td>\n      <td>Rubio: “Rape Victims Should Be In Custody If T...</td>\n      <td>663538460104392704\\t663757208031780864\\t663764...</td>\n      <td>success  fail                      ...</td>\n    </tr>\n    <tr>\n      <th>229</th>\n      <td>421</td>\n      <td>politifact14992</td>\n      <td>http://www.trainnews.info/2018/01/rep-paul-gos...</td>\n      <td>Rep. Paul Gosar Asks Capitol Police to Arrest ...</td>\n      <td>958425300144218112\\t958428242528145409\\t958428...</td>\n      <td>Home Business Online Business Bitcoin Revi...</td>\n    </tr>\n    <tr>\n      <th>230</th>\n      <td>422</td>\n      <td>politifact14158</td>\n      <td>https://web.archive.org/web/20170602190500/htt...</td>\n      <td>WORSE THAN HITLER! Trey Gowdy’s Son Found In A...</td>\n      <td>865933040492703745</td>\n      <td>success  fail                   ...</td>\n    </tr>\n    <tr>\n      <th>231</th>\n      <td>427</td>\n      <td>politifact14944</td>\n      <td>http://thehill.com/homenews/senate/369928-who-...</td>\n      <td>Who is affected by the government shutdown?</td>\n      <td>954602090462146560\\t954602093171609600\\t954650...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>232</th>\n      <td>428</td>\n      <td>politifact14071</td>\n      <td>https://web.archive.org/web/20170322070001/htt...</td>\n      <td>Lindsey Graham Threatens To Convert To Democra...</td>\n      <td>740351669834244096\\t740391312277573632\\t740474...</td>\n      <td>success  fail        ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>205 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "filtered_p_fake = filtered_p_fake[filtered_p_fake['tweet_ids'].notnull()]\n",
    "filtered_p_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/91 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8cba73d254434815b5c079a6929642fc"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "politifact_fake_tweet_times = pd.DataFrame(columns=['news_id', 'timestamps'])\n",
    "politifact_fake_tweet_data = []\n",
    "\n",
    "# for index, tweet_ids in enumerate(tqdm(filtered_p_fake['tweet_ids'])):\n",
    "for index, tweet_ids in enumerate(tqdm(missing_filtered_p_fake['tweet_ids'])):\n",
    "    if type(tweet_ids) != float:\n",
    "        tweet_id_list = tweet_ids.split()\n",
    "        temp_data_for_author = []\n",
    "        temp_list_of_100 = ''\n",
    "        for tweet_index, tweet_id in enumerate(tweet_id_list):\n",
    "            if tweet_index % 100 == 0 and tweet_index > 0:\n",
    "                time.sleep(0.8)\n",
    "                if temp_list_of_100.endswith(','):\n",
    "                    temp_list_of_100 = temp_list_of_100[:-1]\n",
    "                    response = requests.get(f'https://api.twitter.com/2/tweets?ids={temp_list_of_100}&tweet.fields=created_at,author_id',  headers=headers) \n",
    "                    temp_list_of_100 = ''\n",
    "                else:\n",
    "                    response = requests.get(f'https://api.twitter.com/2/tweets?ids={temp_list_of_100}&tweet.fields=created_at,author_id',  headers=headers) \n",
    "                    temp_list_of_100 = ''\n",
    "                try:\n",
    "                    data = response.json()\n",
    "                    # print(response)\n",
    "                    # print(data)\n",
    "                except JSONDecodeError as e:\n",
    "                    continue\n",
    "                if 'data' in data:\n",
    "                    for item in data['data']:\n",
    "                        if 'created_at' in item:\n",
    "                            item['news_id'] = filtered_p_fake.iloc[index]['id']\n",
    "                            if filtered_p_fake.iloc[index]['id'] not in politifact_fake_tweet_dataframe['news_id'].to_list():\n",
    "                                print(filtered_p_fake.iloc[index]['id'])\n",
    "                                politifact_fake_tweet_data.append(item)\n",
    "                    # print(len(data['data']))\n",
    "                    # print(tweet_index)\n",
    "                    # print(index)\n",
    "                    # for tweet in data['data']:\n",
    "                    #     # print(filtered_p_fake.loc[index, 'id'])\n",
    "                    #     if politifact_fake_tweet_times['news_id'].str.contains(filtered_p_fake.loc[index, 'id']).any():\n",
    "                    #         try:\n",
    "                    #             current_index = politifact_fake_tweet_times.index[politifact_fake_tweet_times.news_id == filtered_p_fake.loc[index, 'id']].tolist()[0]\n",
    "                    #             # print(current_index)\n",
    "                    #             created_at = tweet['created_at']\n",
    "                    #             politifact_fake_tweet_times.loc[current_index, 'timestamps'] += f',{created_at}' \n",
    "                    #         except IndexError as e:\n",
    "                    #             print(e)\n",
    "                    #     else: \n",
    "                    #         politifact_fake_tweet_times = politifact_fake_tweet_times.append({'news_id':filtered_p_fake.loc[index, 'id'], 'timestamps':tweet['created_at']}, ignore_index=True)\n",
    "                    #         # print(tweet.created_at)\n",
    "                    #         # print(data['data'][index]['created_at'])\n",
    "                    #         # print('piece_of_news ', filtered_p_fake.loc[index, 'id'])\n",
    "\n",
    "            elif tweet_index % 100 == 99:\n",
    "                temp_list_of_100 = temp_list_of_100 + f'{tweet_id},'\n",
    "            # same if it's the last of the batch we process\n",
    "            elif tweet_index == len(filtered_p_fake['tweet_ids'])-1:\n",
    "                temp_list_of_100 = temp_list_of_100 + f'{tweet_id},'\n",
    "            # otherwise we got to separate with a comma\n",
    "            else:\n",
    "                temp_list_of_100 = temp_list_of_100 + f'{tweet_id},'\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/366 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "27de6924267c40aeabc9cd207b4e4be9"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "politifact_real_tweet_times = pd.DataFrame(columns=['news_id', 'timestamps'])\n",
    "politifact_real_tweet_data = []\n",
    "\n",
    "# for index, tweet_ids in enumerate(tqdm(filtered_p_fake['tweet_ids'])):\n",
    "for index, tweet_ids in enumerate(tqdm(filtered_p_real['tweet_ids'])):\n",
    "    if type(tweet_ids) != float:\n",
    "        tweet_id_list = tweet_ids.split()\n",
    "        temp_data_for_author = []\n",
    "        temp_list_of_100 = ''\n",
    "        for tweet_index, tweet_id in enumerate(tweet_id_list):\n",
    "            if tweet_index % 100 == 0 and tweet_index > 0:\n",
    "                time.sleep(0.8)\n",
    "                if temp_list_of_100.endswith(','):\n",
    "                    temp_list_of_100 = temp_list_of_100[:-1]\n",
    "                    response = requests.get(f'https://api.twitter.com/2/tweets?ids={temp_list_of_100}&tweet.fields=created_at,author_id',  headers=headers) \n",
    "                    temp_list_of_100 = ''\n",
    "                else:\n",
    "                    response = requests.get(f'https://api.twitter.com/2/tweets?ids={temp_list_of_100}&tweet.fields=created_at,author_id',  headers=headers) \n",
    "                    temp_list_of_100 = ''\n",
    "                try:\n",
    "                    data = response.json()\n",
    "                    # print(response)\n",
    "                    # print(data)\n",
    "                except JSONDecodeError as e:\n",
    "                    continue\n",
    "                if 'data' in data:\n",
    "                    for item in data['data']:\n",
    "                        if 'created_at' in item:\n",
    "                            item['news_id'] = filtered_p_real.iloc[index]['id']\n",
    "                            # if filtered_p_real.iloc[index]['id'] not in politifact_real_tweet_dataframe['news_id'].to_list():\n",
    "                                # print(filtered_p_fake.iloc[index]['id'])\n",
    "                            politifact_real_tweet_data.append(item)\n",
    "                    # print(len(data['data']))\n",
    "                    # print(tweet_index)\n",
    "                    # print(index)\n",
    "                    # for tweet in data['data']:\n",
    "                    #     # print(filtered_p_fake.loc[index, 'id'])\n",
    "                    #     if politifact_fake_tweet_times['news_id'].str.contains(filtered_p_fake.loc[index, 'id']).any():\n",
    "                    #         try:\n",
    "                    #             current_index = politifact_fake_tweet_times.index[politifact_fake_tweet_times.news_id == filtered_p_fake.loc[index, 'id']].tolist()[0]\n",
    "                    #             # print(current_index)\n",
    "                    #             created_at = tweet['created_at']\n",
    "                    #             politifact_fake_tweet_times.loc[current_index, 'timestamps'] += f',{created_at}' \n",
    "                    #         except IndexError as e:\n",
    "                    #             print(e)\n",
    "                    #     else: \n",
    "                    #         politifact_fake_tweet_times = politifact_fake_tweet_times.append({'news_id':filtered_p_fake.loc[index, 'id'], 'timestamps':tweet['created_at']}, ignore_index=True)\n",
    "                    #         # print(tweet.created_at)\n",
    "                    #         # print(data['data'][index]['created_at'])\n",
    "                    #         # print('piece_of_news ', filtered_p_fake.loc[index, 'id'])\n",
    "\n",
    "            elif tweet_index % 100 == 99:\n",
    "                temp_list_of_100 = temp_list_of_100 + f'{tweet_id},'\n",
    "            # same if it's the last of the batch we process\n",
    "            elif tweet_index == len(filtered_p_real['tweet_ids'])-1:\n",
    "                temp_list_of_100 = temp_list_of_100 + f'{tweet_id},'\n",
    "            # otherwise we got to separate with a comma\n",
    "            else:\n",
    "                temp_list_of_100 = temp_list_of_100 + f'{tweet_id},'\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "politifact_real_tweet_dataframe = pd.DataFrame(politifact_real_tweet_data)\n",
    "# politifact_real_tweet_dataframe = politifact_real_tweet_dataframe.append(politifact_real_tweet_data, ignore_index=True)\n",
    "politifact_real_tweet_dataframe.to_csv('processed-data/politifact_real_tweet_times.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "metadata": {},
     "execution_count": 184
    }
   ],
   "source": [
    "len(politifact_real_tweet_dataframe['news_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# politifact_fake_tweet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "politifact_fake_tweet_dataframe = politifact_fake_tweet_dataframe.append(politifact_fake_tweet_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "politifact_fake_tweet_dataframe.to_csv('processed-data/politifact_fake_tweet_times.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "78500"
      ]
     },
     "metadata": {},
     "execution_count": 162
    }
   ],
   "source": [
    "len(politifact_fake_tweet_dataframe['id'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_politifact = politifact_fake_tweet_dataframe['news_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_filtered_p_fake = filtered_p_fake[~filtered_p_fake['id'].isin(collected_politifact)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "politifact_fake_times = pd.DataFrame(columns=['id','timestamps'])\n",
    "for index, item in enumerate(politifact_fake_tweet_data):\n",
    "    for k in item:\n",
    "        for item_index, j in enumerate(item[k]):\n",
    "            if 'created_at' in j:\n",
    "                if politifact_fake_times['id'].str.contains(j['id']).any():\n",
    "                    try:\n",
    "                        current_index = politifact_fake_times.index[politifact_fake_times.id == j['id']].tolist()[0]\n",
    "                        politifact_fake_times.loc[current_index, 'timestamps'] += j['created_at']\n",
    "                    except IndexError as e:\n",
    "                        print(e)\n",
    "                else: \n",
    "                    politifact_fake_times = politifact_fake_times.append({'id':j['id'], 'timestamps':j['created_at']}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                        id                timestamps\n",
       "0       978246351036264453  2018-03-26T12:24:39.000Z\n",
       "1       978246559472275456  2018-03-26T12:25:29.000Z\n",
       "2       978246571128250368  2018-03-26T12:25:32.000Z\n",
       "3       978246651491094528  2018-03-26T12:25:51.000Z\n",
       "4       978247005481947136  2018-03-26T12:27:15.000Z\n",
       "...                    ...                       ...\n",
       "20947  1012345194983907328  2018-06-28T14:41:17.000Z\n",
       "20948  1012345247916003328  2018-06-28T14:41:30.000Z\n",
       "20949  1012345635062853634  2018-06-28T14:43:02.000Z\n",
       "20950  1012345706085011456  2018-06-28T14:43:19.000Z\n",
       "20951  1012345764033519616  2018-06-28T14:43:33.000Z\n",
       "\n",
       "[20952 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>timestamps</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>978246351036264453</td>\n      <td>2018-03-26T12:24:39.000Z</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>978246559472275456</td>\n      <td>2018-03-26T12:25:29.000Z</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>978246571128250368</td>\n      <td>2018-03-26T12:25:32.000Z</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>978246651491094528</td>\n      <td>2018-03-26T12:25:51.000Z</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>978247005481947136</td>\n      <td>2018-03-26T12:27:15.000Z</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20947</th>\n      <td>1012345194983907328</td>\n      <td>2018-06-28T14:41:17.000Z</td>\n    </tr>\n    <tr>\n      <th>20948</th>\n      <td>1012345247916003328</td>\n      <td>2018-06-28T14:41:30.000Z</td>\n    </tr>\n    <tr>\n      <th>20949</th>\n      <td>1012345635062853634</td>\n      <td>2018-06-28T14:43:02.000Z</td>\n    </tr>\n    <tr>\n      <th>20950</th>\n      <td>1012345706085011456</td>\n      <td>2018-06-28T14:43:19.000Z</td>\n    </tr>\n    <tr>\n      <th>20951</th>\n      <td>1012345764033519616</td>\n      <td>2018-06-28T14:43:33.000Z</td>\n    </tr>\n  </tbody>\n</table>\n<p>20952 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "politifact_fake_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n"
     ]
    }
   ],
   "source": [
    "tweet_times_g_fake = pd.DataFrame(columns=[\"id\", \"timestamps\"])\n",
    "for index, item in enumerate(politifact_fake_tweet_data):\n",
    "    for k in item:\n",
    "        for item_index, j in enumerate(item[k]):\n",
    "            if 'id' in j:\n",
    "                if tweet_times_p_fake['id'].str.contains(j['id']).any():\n",
    "                    try:\n",
    "                        current_index = tweet_times_p_fake.index[tweet_times_p_fake.id == j['id']].to_list()[0]\n",
    "                        tweet_times_p_fake.loc[current_index, 'timestamps'] += j['created_at']\n",
    "                    except IndexError as e:\n",
    "                        print(e)\n",
    "                else:\n",
    "                    tweet_times_p_fake = tweet_times_p_fake.append({'id':j['id'], 'timestamps':j['created_at']}, ignore_index=True)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                author_id tweets real_count fake_count\n",
       "32764  710856880680275969    NaN          0        311\n",
       "32928           144222146    NaN          0        266\n",
       "40659            18000449    NaN          0        185\n",
       "40553            23772575    NaN          0        133\n",
       "40578  790019230389248000    NaN          0         58\n",
       "...                   ...    ...        ...        ...\n",
       "15422            16377693    NaN          1          0\n",
       "15423            64465376    NaN          1          0\n",
       "15424            44999215    NaN          1          0\n",
       "15425            25969442    NaN          1          0\n",
       "22916            15469048    NaN          1          0\n",
       "\n",
       "[45833 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author_id</th>\n      <th>tweets</th>\n      <th>real_count</th>\n      <th>fake_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>32764</th>\n      <td>710856880680275969</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>311</td>\n    </tr>\n    <tr>\n      <th>32928</th>\n      <td>144222146</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>266</td>\n    </tr>\n    <tr>\n      <th>40659</th>\n      <td>18000449</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>185</td>\n    </tr>\n    <tr>\n      <th>40553</th>\n      <td>23772575</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>133</td>\n    </tr>\n    <tr>\n      <th>40578</th>\n      <td>790019230389248000</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15422</th>\n      <td>16377693</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15423</th>\n      <td>64465376</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15424</th>\n      <td>44999215</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15425</th>\n      <td>25969442</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22916</th>\n      <td>15469048</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>45833 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "tweets_by_author.sort_values(by=['fake_count'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                author_id tweets real_count fake_count\n",
       "44              612797013    NaN          8          1\n",
       "160              56135553    NaN          1          1\n",
       "199              49800332    NaN          2          1\n",
       "212             262797667    NaN          2          1\n",
       "215             566828522    NaN          1          1\n",
       "...                   ...    ...        ...        ...\n",
       "30396  946822648729915393    NaN          1          1\n",
       "30476           125767959    NaN          1          6\n",
       "30502           105272579    NaN          3          1\n",
       "30635            27229155    NaN          1          1\n",
       "30638            25432802    NaN          1          8\n",
       "\n",
       "[1258 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author_id</th>\n      <th>tweets</th>\n      <th>real_count</th>\n      <th>fake_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>44</th>\n      <td>612797013</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>160</th>\n      <td>56135553</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>49800332</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>212</th>\n      <td>262797667</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>215</th>\n      <td>566828522</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>30396</th>\n      <td>946822648729915393</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>30476</th>\n      <td>125767959</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>30502</th>\n      <td>105272579</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>30635</th>\n      <td>27229155</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>30638</th>\n      <td>25432802</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n<p>1258 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "test = tweets_by_author[tweets_by_author['fake_count']!=0]\n",
    "test = test[test['real_count']!=0]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_p_real = filtered_p_real[filtered_p_real['tweet_ids'].notnull()]\n",
    "\n",
    "def getTweetAuthors(tweet_ids_raw):\n",
    "    count = 0\n",
    "    print(tweet_ids_raw)\n",
    "    tweet_ids = re.split(r'\\\\t', tweet_ids_raw)\n",
    "    for tweet_id in tweet_ids:\n",
    "        if count < 1:\n",
    "            response = requests.get('https://api.twitter.com/2/tweets?ids={tweet_id}&tweet.fields=created_at&expansions=author_id&user.fields=created_at',  headers)\n",
    "            count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_by_author.to_csv(\"processed-data/tweets-by-author-politifact.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}